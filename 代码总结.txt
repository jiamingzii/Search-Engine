================================================================================
PROJECT CODEBASE - MERGED SOURCE FILES
================================================================================
Generated: 2025-12-29 09:59:51
Project: Engine
Total Files: 30

READING GUIDE:
- Each file section starts with a header containing file name and path
- Files are separated by '=' lines
- Path: shows the relative path from project root
- Type: indicates the file type for syntax reference

--------------------------------------------------------------------------------
FILE INDEX:
--------------------------------------------------------------------------------
   1. include\Configuration.h
   2. include\DictProducer.h
   3. include\InvertIndex.h
   4. include\KeywordRecommender.h
   5. include\LRUCache.h
   6. include\PageLib.h
   7. include\PageLibPreprocessor.h
   8. include\SearchServer.h
   9. include\SplitTool.h
  10. include\WebPage.h
  11. include\WebPageMeta.h
  12. debug_search.cc
  13. src\Configuration.cc
  14. src\DictProducer.cc
  15. src\InvertIndex.cc
  16. src\KeywordRecommender.cc
  17. src\PageLib.cc
  18. src\PageLibPreprocessor.cc
  19. src\SearchServer.cc
  20. src\SplitTool.cc
  21. src\WebPage.cc
  22. src\main.cc
  23. Makefile
  24. README.md
  25. conf\search.conf
  26. static\index.html
  27. å‹åŠ›æµ‹è¯•.md
  28. é¢è¯•æŒ‡å¯¼.md
  29. é¡¹ç›®æ”¹è¿›.md
  30. é¡¹ç›®ç»“æ„.md

================================================================================
File: Configuration.h
Path: include\Configuration.h
Type: cpp
================================================================================
#ifndef __CONFIGURATION_H__
#define __CONFIGURATION_H__

#include <string>
#include <map>

using std::string;
using std::map;

// é…ç½®æ–‡ä»¶å•ä¾‹ç±»
class Configuration {
public:
    static Configuration* getInstance();

    void load(const string& configPath);
    string get(const string& key) const;

private:
    Configuration() = default;
    ~Configuration() = default;
    Configuration(const Configuration&) = delete;
    Configuration& operator=(const Configuration&) = delete;

private:
    static Configuration* _pInstance;
    map<string, string> _configs;
};

#endif // __CONFIGURATION_H__

================================================================================
File: DictProducer.h
Path: include\DictProducer.h
Type: cpp
================================================================================
#ifndef __DICT_PRODUCER_H__
#define __DICT_PRODUCER_H__

#include <string>
#include <vector>
#include <map>
#include <set>
#include <memory>

using std::string;
using std::vector;
using std::map;
using std::set;
using std::shared_ptr;

class SplitTool;
class WebPage;

// è¯å…¸ç”Ÿæˆå™¨ï¼šä»è¯­æ–™ä¸­æå–è¯å…¸å’Œç´¢å¼•
class DictProducer {
public:
    DictProducer(SplitTool* splitTool);

    // ä»ç½‘é¡µåº“æ„å»ºè¯å…¸
    void build(const vector<shared_ptr<WebPage>>& pages);
    // ä»æ–‡æœ¬æ–‡ä»¶æ„å»ºè¯å…¸ï¼ˆä¸€è¡Œä¸€ä¸ªæ–‡æ¡£ï¼‰
    void buildFromFile(const string& filePath);

    // å­˜å‚¨è¯å…¸åˆ°æ–‡ä»¶
    void storeDict(const string& filePath);
    // åŠ è½½è¯å…¸
    void loadDict(const string& filePath);
    
    // å­˜å‚¨å­—ç¬¦ç´¢å¼•åˆ°æ–‡ä»¶
    void storeIndex(const string& filePath);
    // åŠ è½½å­—ç¬¦ç´¢å¼•
    void loadIndex(const string& filePath);

    // è·å–è¯å…¸ï¼ˆword -> frequencyï¼‰
    const map<string, int>& getDict() const { return _dict; }

    // æ ¹æ®å­—ç¬¦è·å–å€™é€‰è¯
    vector<string> getCandidates(const string& prefix) const;

private:
    // æ„å»ºå­—ç¬¦ç´¢å¼•
    void buildIndex();

    // åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡å­—ç¬¦
    bool isChinese(const string& ch) const;

    // æå–å­—ç¬¦ä¸²çš„æ‰€æœ‰å­—ç¬¦ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰
    vector<string> extractChars(const string& word) const;

private:
    SplitTool* _splitTool;

    // è¯å…¸ï¼šè¯ -> è¯é¢‘
    map<string, int> _dict;

    // å­—ç¬¦ç´¢å¼•ï¼šå­—ç¬¦ -> åŒ…å«è¯¥å­—ç¬¦çš„è¯åˆ—è¡¨
    map<string, set<string>> _charIndex;
};

#endif // __DICT_PRODUCER_H__

================================================================================
File: InvertIndex.h
Path: include\InvertIndex.h
Type: cpp
================================================================================
#ifndef __INVERT_INDEX_H__
#define __INVERT_INDEX_H__

#include <string>
#include <vector>
#include <map>
#include <unordered_map> // ä¼˜åŒ–: å¼•å…¥å“ˆå¸Œè¡¨
#include <memory>

using std::string;
using std::vector;
using std::map;
using std::unordered_map;
using std::pair;
using std::shared_ptr;

class WebPage;

// å€’æ’ç´¢å¼•é¡¹ï¼šæ–‡æ¡£ID + æƒé‡
// ä¼˜åŒ–: ä¿æŒ POD ç»“æ„ï¼Œå†…å­˜å¸ƒå±€ç´§å‡‘
struct InvertIndexItem {
     // BM25 æƒé‡
    double weight; //å½“å‰è¯ï¼ˆTermï¼‰åœ¨å½“å‰æ–‡æ¡£ï¼ˆDocï¼‰ä¸­çš„é‡è¦ç¨‹åº¦è¯„åˆ†
    int docId;
    int termFreq;   // è¯¥è¯å‡ºç°åœ¨è¯¥æ–‡æ¡£çš„æ¬¡æ•°ï¼ˆè¯é¢‘ï¼‰
};

class InvertIndex {
public:
    InvertIndex();
    //ä¸ºè®¡ç®—BM25åšå‡†å¤‡
    void build(vector<shared_ptr<WebPage>>& pages);

    //  å¢æ ¹æ®æŸ¥è¯¢è¯æœç´¢æƒé‡æœ€å¤§çš„å‰20ä¸ª
    vector<pair<int, double>> search(const vector<string>& queryWords, int topK = 20);
    //å­˜å‚¨ å’Œ åŠ è½½ ç½‘é¡µ
    void store(const string& filePath);
    void load(const string& filePath);

    int getTotalDocs() const { return _totalDocs; }

private:
    static constexpr double K1 = 1.2;
    static constexpr double B = 0.75;

    double calculateIDF(int docFreq, int totalDocs);
    double calculateBM25(int termFreq, int docLen, int docFreq);

private:
    // ä¼˜åŒ–: ä½¿ç”¨ unordered_map æ›¿ä»£ mapï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡è‡³ O(1)
    unordered_map<string, vector<InvertIndexItem>> _invertIndex;

    map<int, int> _docLens; //æ¯ä¸ªæ–‡æ¡£ï¼ˆå­˜å‚¨IDï¼‰å¯¹åº”çš„é•¿åº¦
    int _totalDocs;//æ€»çš„æ–‡ä»¶æ•°
    double _avgDocLen;//å¹³å‡æ–‡ä»¶é•¿åº¦
};

#endif // __INVERT_INDEX_H__

================================================================================
File: KeywordRecommender.h
Path: include\KeywordRecommender.h
Type: cpp
================================================================================
#ifndef __KEYWORD_RECOMMENDER_H__
#define __KEYWORD_RECOMMENDER_H__

#include <string>
#include <vector>
#include <map>
#include <set>
#include <queue>

using std::string;
using std::vector;
using std::map;
using std::set;
using std::priority_queue;
using std::pair;

class DictProducer;

// å€™é€‰è¯ç»“æ„
struct CandidateWord {
    string word;
    int distance;   // ç¼–è¾‘è·ç¦»
    int frequency;  // è¯é¢‘

    // ä¼˜å…ˆçº§ï¼šè·ç¦»å°çš„ä¼˜å…ˆï¼Œè·ç¦»ç›¸åŒæ—¶è¯é¢‘é«˜çš„ä¼˜å…ˆ
    bool operator<(const CandidateWord& other) const {
        if (distance != other.distance) {
            return distance > other.distance;  // è·ç¦»å°çš„ä¼˜å…ˆ
        }
        return frequency < other.frequency;  // è¯é¢‘é«˜çš„ä¼˜å…ˆ
    }
};

// å…³é”®è¯æ¨èå™¨ï¼šåŸºäºæœ€å°ç¼–è¾‘è·ç¦»
class KeywordRecommender {
public:
    KeywordRecommender(const DictProducer* dictProducer);

    // è·å–æ¨èè¯åˆ—è¡¨
    vector<string> recommend(const string& query, int topK = 5, int maxDistance = 3);

    // è®¡ç®—æœ€å°ç¼–è¾‘è·ç¦»
    static int editDistance(const string& s1, const string& s2);

private:
    // å°†å­—ç¬¦ä¸²æ‹†åˆ†ä¸º UTF-8 å­—ç¬¦æ•°ç»„
    static vector<string> splitToChars(const string& s);

private:
    const DictProducer* _dictProducer;
};

#endif // __KEYWORD_RECOMMENDER_H__

================================================================================
File: LRUCache.h
Path: include\LRUCache.h
Type: cpp
================================================================================
#ifndef __SEARCH_LRU_CACHE_H__
#define __SEARCH_LRU_CACHE_H__

#include <list>
#include <unordered_map>
#include <string>
#include <mutex>
#include <array>
#include <atomic>
#include <functional>

using std::list;
using std::unordered_map;
using std::string;
using std::pair;
using std::mutex;
using std::lock_guard;

// å•ä¸ª LRU åˆ†ç‰‡
template<typename K, typename V>
class LRUShard {
public:
    explicit LRUShard(size_t capacity)
        : _capacity(capacity) {
    }

    bool get(const K& key, V& value) {
        lock_guard<mutex> lock(_mutex);
        auto it = _index.find(key);
        if (it == _index.end()) {
            return false;
        }
        _cache.splice(_cache.begin(), _cache, it->second);
        value = it->second->second;
        return true;
    }

    void put(const K& key, const V& value) {
        lock_guard<mutex> lock(_mutex);
        auto it = _index.find(key);
        if (it != _index.end()) {
            it->second->second = value;
            _cache.splice(_cache.begin(), _cache, it->second);
            return;
        }
        if (_cache.size() >= _capacity) {
            auto last = _cache.back();
            _index.erase(last.first);
            _cache.pop_back();
        }
        _cache.push_front({key, value});
        _index[key] = _cache.begin();
    }

    bool contains(const K& key) {
        lock_guard<mutex> lock(_mutex);
        return _index.find(key) != _index.end();
    }

    size_t size() {
        lock_guard<mutex> lock(_mutex);
        return _cache.size();
    }

    void clear() {
        lock_guard<mutex> lock(_mutex);
        _cache.clear();
        _index.clear();
    }

private:
    size_t _capacity;
    list<pair<K, V>> _cache;
    unordered_map<K, typename list<pair<K, V>>::iterator> _index;
    mutex _mutex;
};

// åˆ†æ®µé” LRU ç¼“å­˜
template<typename K, typename V, size_t ShardCount = 16>
class ShardedLRUCache {
public:
    explicit ShardedLRUCache(size_t totalCapacity)
        : _totalCapacity(totalCapacity) {
        size_t perShardCapacity = std::max(totalCapacity / ShardCount, (size_t)1);
        for (size_t i = 0; i < ShardCount; ++i) {
            _shards[i] = std::make_unique<LRUShard<K, V>>(perShardCapacity);
        }
    }

    bool get(const K& key, V& value) {
        return getShard(key).get(key, value);
    }

    void put(const K& key, const V& value) {
        getShard(key).put(key, value);
    }

    bool contains(const K& key) {
        return getShard(key).contains(key);
    }

    size_t size() {
        size_t total = 0;
        for (size_t i = 0; i < ShardCount; ++i) {
            total += _shards[i]->size();
        }
        return total;
    }

    void clear() {
        for (size_t i = 0; i < ShardCount; ++i) {
            _shards[i]->clear();
        }
    }

    double hitRate() const {
        size_t total = _totalQueries.load();
        if (total == 0) return 0;
        return (double)_hits.load() / total;
    }

    void recordQuery(bool hit) {
        _totalQueries.fetch_add(1, std::memory_order_relaxed);
        if (hit) {
            _hits.fetch_add(1, std::memory_order_relaxed);
        }
    }

private:
    LRUShard<K, V>& getShard(const K& key) {
        size_t hash = std::hash<K>{}(key);
        return *_shards[hash % ShardCount];
    }

    size_t _totalCapacity;
    std::array<std::unique_ptr<LRUShard<K, V>>, ShardCount> _shards;
    std::atomic<size_t> _totalQueries{0};
    std::atomic<size_t> _hits{0};
};

// ä¿æŒå‘åå…¼å®¹çš„ç±»å‹åˆ«å
template<typename K, typename V>
using SearchLRUCache = ShardedLRUCache<K, V, 16>;

using SearchCache = SearchLRUCache<string, string>;

#endif

================================================================================
File: PageLib.h
Path: include\PageLib.h
Type: cpp
================================================================================
#ifndef __PAGE_LIB_H__
#define __PAGE_LIB_H__

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include "WebPageMeta.h"

using std::string;
using std::vector;
using std::shared_ptr;
using std::unordered_map;

class WebPage;
class SplitTool;

// ç½‘é¡µåº“ï¼šç®¡ç†æ‰€æœ‰ç½‘é¡µ
class PageLib {
public:
    PageLib(const string& dataPath, SplitTool* splitTool);

    // ä»æ–‡ä»¶åŠ è½½ç½‘é¡µ
    void load();

    // è·å–æ‰€æœ‰ç½‘é¡µ
    vector<shared_ptr<WebPage>>& getPages() { return _pages; }

    // å­˜å‚¨ç½‘é¡µåº“åˆ°æ–‡ä»¶
    void store(const string& outputPath);

    // === æ–°å¢ï¼šè½»é‡çº§å­˜å‚¨æ–¹æ¡ˆ ===
    // åˆ†ç¦»å­˜å‚¨ï¼šå…ƒæ•°æ®æ–‡ä»¶ + å†…å®¹æ–‡ä»¶
    void storeSeparated(const string& metaPath, const string& contentPath);

    // åŠ è½½è½»é‡çº§å…ƒæ•°æ®ï¼ˆä¸åŠ è½½æ­£æ–‡å†…å®¹ï¼‰
    static unordered_map<int, WebPageMeta> loadMeta(const string& metaPath);

private:
    // è§£æå•ä¸ªæ–‡ä»¶
    void parseFile(const string& filePath);

private:
    string _dataPath;
    SplitTool* _splitTool;
    vector<shared_ptr<WebPage>> _pages;
};

#endif // __PAGE_LIB_H__

================================================================================
File: PageLibPreprocessor.h
Path: include\PageLibPreprocessor.h
Type: cpp
================================================================================
#ifndef __PAGE_LIB_PREPROCESSOR_H__
#define __PAGE_LIB_PREPROCESSOR_H__

#include <string>
#include <vector>
#include <set>
#include <memory>

using std::string;
using std::vector;
using std::set;
using std::shared_ptr;

class WebPage;
class SplitTool;

// ç½‘é¡µé¢„å¤„ç†å™¨ï¼šå»é‡ã€æ„å»ºç´¢å¼•
class PageLibPreprocessor {
public:
    PageLibPreprocessor(vector<shared_ptr<WebPage>>& pages, SplitTool* splitTool);

    // ç½‘é¡µå»é‡ï¼ˆåŸºäº SimHashï¼‰
    void deduplicate();

    // è·å–å»é‡åçš„ç½‘é¡µ
    vector<shared_ptr<WebPage>>& getProcessedPages() { return _processedPages; }

private:
    // åˆ¤æ–­ä¸¤ä¸ª SimHash æ˜¯å¦ç›¸ä¼¼ï¼ˆæ±‰æ˜è·ç¦» < é˜ˆå€¼ï¼‰
    bool isSimilar(uint64_t hash1, uint64_t hash2, int threshold = 3);

private:
    vector<shared_ptr<WebPage>>& _pages;
    vector<shared_ptr<WebPage>> _processedPages;
    SplitTool* _splitTool;
};

#endif // __PAGE_LIB_PREPROCESSOR_H__

================================================================================
File: SearchServer.h
Path: include\SearchServer.h
Type: cpp
================================================================================
#ifndef __SEARCH_SERVER_H__
#define __SEARCH_SERVER_H__

#include <string>
#include <memory>
#include <vector>
#include <map>
#include <unordered_map>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include "LRUCache.h"
#include "WebPageMeta.h"

using std::string;
using std::shared_ptr;
using std::vector;
using std::map;
using std::unordered_map;
using std::pair;

class InvertIndex;
class SplitTool;
class WebPage;
class DictProducer;
class KeywordRecommender;

// æœç´¢æœåŠ¡å™¨ï¼šåŸºäº wfrest çš„ HTTP æœåŠ¡
class SearchServer {
public:
    SearchServer(const string& ip, int port,
                 shared_ptr<InvertIndex> index,
                 SplitTool* splitTool);

    // è®¾ç½®ç½‘é¡µåº“å¼•ç”¨ï¼ˆç”¨äºè·å–æ ‡é¢˜ã€æ‘˜è¦ç­‰ï¼‰- ä¼ ç»Ÿæ¨¡å¼
    void setPageLib(const map<int, shared_ptr<WebPage>>& pageLib);

    // è®¾ç½®è½»é‡çº§ç½‘é¡µåº“ï¼ˆå†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼‰
    void setPageLibLite(const unordered_map<int, WebPageMeta>& pageMeta,
                        const string& contentFilePath);

    // è®¾ç½®è¯å…¸å’Œæ¨èå™¨ï¼ˆå¯é€‰ï¼‰
    void setDictProducer(shared_ptr<DictProducer> dictProducer);
    void setRecommender(shared_ptr<KeywordRecommender> recommender);

    // è®¾ç½®ç¼“å­˜å¤§å°
    void setCacheCapacity(size_t capacity);

    // å¯åŠ¨æœåŠ¡
    void start();

    // åœæ­¢æœåŠ¡
    void stop();

private:
    // å¤„ç†æœç´¢è¯·æ±‚
    string handleSearch(const string& query);

    // å¤„ç†å…³é”®è¯æ¨èè¯·æ±‚
    string handleSuggest(const string& query);

    // ç”Ÿæˆ JSON å“åº”
    string generateResponse(const string& query,
                           const vector<pair<int, double>>& results,
                           const vector<string>& queryWords);

    // ç”Ÿæˆæ¨èè¯ JSON å“åº”
    string generateSuggestResponse(const string& query,
                                   const vector<string>& suggestions);

private:
    string _ip;
    int _port;
    shared_ptr<InvertIndex> _index;
    SplitTool* _splitTool;

    // ç½‘é¡µåº“ï¼šdocId -> WebPageï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
    map<int, shared_ptr<WebPage>> _pageLib;

    // è½»é‡çº§ç½‘é¡µåº“ï¼ˆå†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼‰
    unordered_map<int, WebPageMeta> _pageMetaLib;
    shared_ptr<ContentStore> _contentStore;
    bool _useLiteMode = false;

    // è¯å…¸ç”Ÿæˆå™¨å’Œå…³é”®è¯æ¨èå™¨
    shared_ptr<DictProducer> _dictProducer;
    shared_ptr<KeywordRecommender> _recommender;

    // LRU ç¼“å­˜
    shared_ptr<SearchCache> _cache;

    // ä¼˜é›…é€€å‡ºæ§åˆ¶
    std::mutex _shutdownMutex;
    std::condition_variable _shutdownCv;
    std::atomic<bool> _running{false};
};

#endif // __SEARCH_SERVER_H__

================================================================================
File: SplitTool.h
Path: include\SplitTool.h
Type: cpp
================================================================================
#ifndef __SPLIT_TOOL_H__
#define __SPLIT_TOOL_H__

#include <string>
#include <vector>
#include <memory>

using std::string;
using std::vector;

// åˆ†è¯å·¥å…·åŸºç±»
class SplitTool {
public:
    virtual ~SplitTool() = default;
    virtual vector<string> cut(const string& sentence) = 0;
};

// ç»“å·´åˆ†è¯å®ç°
class JiebaSplitTool : public SplitTool {
public:
    JiebaSplitTool(const string& dictPath,
                   const string& modelPath,
                   const string& userDictPath,
                   const string& idfPath,
                   const string& stopWordPath);
    ~JiebaSplitTool();

    vector<string> cut(const string& sentence) override;

private:
    class Impl;  // pImpl æ¨¡å¼ï¼Œéšè— cppjieba å¤´æ–‡ä»¶ä¾èµ–
    std::unique_ptr<Impl> _pImpl;
};

#endif // __SPLIT_TOOL_H__

================================================================================
File: WebPage.h
Path: include\WebPage.h
Type: cpp
================================================================================
#ifndef __WEB_PAGE_H__
#define __WEB_PAGE_H__

#include <string>
#include <vector>
#include <map>
#include <cstdint>

using std::string;
using std::vector;
using std::map;

class SplitTool;

// ç½‘é¡µç±»ï¼šè¡¨ç¤ºä¸€ä¸ªæ–‡æ¡£
class WebPage {
public:
    WebPage(const string& doc, SplitTool* splitTool);

    int getDocId() const { return _docId; }
    string getTitle() const { return _title; }
    string getUrl() const { return _url; }
    string getContent() const { return _content; }

    // è·å–è¯é¢‘ç»Ÿè®¡
    map<string, int>& getWordsMap() { return _wordsMap; }

    // è®¡ç®— SimHash ç”¨äºå»é‡ï¼ˆçœŸæ­£çš„ SimHash å®ç°ï¼‰
    uint64_t getSimhash() const;

    // å¤„ç†æ–‡æ¡£ï¼šæå–æ ‡é¢˜ã€å†…å®¹ã€åˆ†è¯
    void processDoc(const string& doc);

    // ç”Ÿæˆæ‘˜è¦ï¼ˆå¸¦æŸ¥è¯¢è¯ä¸Šä¸‹æ–‡ï¼‰
    string getSummary(const vector<string>& queryWords) const;

    // SimHash ç›¸å…³é™æ€æ–¹æ³•
    static int hammingDistance(uint64_t h1, uint64_t h2);
    static bool isSimilar(uint64_t h1, uint64_t h2, int threshold = 3);

private:
    static int _idGen;  // æ–‡æ¡£ ID ç”Ÿæˆå™¨

    int _docId;
    string _title;
    string _url;
    string _content;

    SplitTool* _splitTool;
    map<string, int> _wordsMap;  // è¯é¢‘ç»Ÿè®¡
};

#endif // __WEB_PAGE_H__

================================================================================
File: WebPageMeta.h
Path: include\WebPageMeta.h
Type: cpp
================================================================================
#ifndef __WEB_PAGE_META_H__
#define __WEB_PAGE_META_H__

#include <string>
#include <fstream>
#include <vector>
#include <memory>

using std::string;
using std::vector;

// è½»é‡çº§ç½‘é¡µå…ƒæ•°æ®ï¼ˆä¸å­˜å‚¨æ­£æ–‡å†…å®¹ï¼‰
struct WebPageMeta {
    int docId;
    string title;
    string url;
    size_t contentOffset;  // æ­£æ–‡åœ¨æ–‡ä»¶ä¸­çš„åç§»é‡
    size_t contentLength;  // æ­£æ–‡é•¿åº¦

    WebPageMeta() : docId(0), contentOffset(0), contentLength(0) {}
};

// å†…å®¹å­˜å‚¨å™¨ï¼šè´Ÿè´£ä»ç£ç›˜è¯»å–æ­£æ–‡
class ContentStore {
public:
    explicit ContentStore(const string& contentFilePath)
        : _filePath(contentFilePath) {
    }

    // æ ¹æ®åç§»é‡è¯»å–å†…å®¹
    string readContent(size_t offset, size_t length) const {
        std::ifstream ifs(_filePath, std::ios::binary);
        if (!ifs) {
            return "";
        }
        ifs.seekg(offset);
        string content(length, '\0');
        ifs.read(&content[0], length);
        return content;
    }

    // ç”Ÿæˆæ‘˜è¦ï¼ˆå»¶è¿Ÿè¯»å–ç‰ˆæœ¬ï¼‰
    string getSummary(size_t offset, size_t length,
                      const vector<string>& queryWords,
                      size_t maxChars = 150) const {
        // åªè¯»å–éœ€è¦çš„éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ­£æ–‡
        // ä¸ºäº†æ‰¾åˆ°å…³é”®è¯ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å…ˆè¯»å–ä¸€éƒ¨åˆ†
        size_t readLength = std::min(length, (size_t)5000);  // æœ€å¤šè¯»å–5KBç”¨äºæ‘˜è¦

        std::ifstream ifs(_filePath, std::ios::binary);
        if (!ifs) {
            return "";
        }
        ifs.seekg(offset);
        string text(readLength, '\0');
        ifs.read(&text[0], readLength);

        if (text.empty()) return "";

        size_t start = 0;
        for (const auto& word : queryWords) {
            size_t pos = text.find(word);
            if (pos != string::npos && pos > 30) {
                start = pos - 30;
                break;
            }
        }

        size_t charCount = 0;
        size_t endPos = start;

        while (endPos < text.length() && charCount < maxChars) {
            unsigned char c = text[endPos];
            size_t charLen = 1;
            if ((c & 0x80) == 0) charLen = 1;
            else if ((c & 0xE0) == 0xC0) charLen = 2;
            else if ((c & 0xF0) == 0xE0) charLen = 3;
            else if ((c & 0xF8) == 0xF0) charLen = 4;

            if (endPos + charLen > text.length()) break;
            endPos += charLen;
            charCount++;
        }

        string summary = text.substr(start, endPos - start);
        if (start > 0) summary = "..." + summary;
        if (endPos < text.length()) summary += "...";

        return summary;
    }

private:
    string _filePath;
};

#endif // __WEB_PAGE_META_H__

================================================================================
File: debug_search.cc
Path: debug_search.cc
Type: cpp
================================================================================
// è°ƒè¯•è„šæœ¬ï¼šæ£€æŸ¥åˆ†è¯å’Œç´¢å¼•é—®é¢˜
#include "Configuration.h"
#include "SplitTool.h"
#include "InvertIndex.h"
#include <iostream>
#include <memory>

using std::cout;
using std::make_shared;

int main() {
    // åŠ è½½é…ç½®
    Configuration* config = Configuration::getInstance();
    config->load("conf/search.conf");

    // åˆå§‹åŒ–åˆ†è¯å·¥å…·
    auto splitTool = make_shared<JiebaSplitTool>(
        config->get("dict_path"),
        config->get("model_path"),
        config->get("user_dict_path"),
        config->get("idf_path"),
        config->get("stop_word_path")
    );

    // æµ‹è¯•åˆ†è¯
    cout << "=== åˆ†è¯æµ‹è¯• ===\n";
    vector<string> testQueries = {"å¥åº·", "ç§‘æŠ€", "æ•™è‚²", "æˆ¿äº§", "ä½“è‚²", "ç§‘å­¦"};

    for (const auto& query : testQueries) {
        cout << "æŸ¥è¯¢è¯: \"" << query << "\" -> åˆ†è¯ç»“æœ: [";
        auto words = splitTool->cut(query);
        for (size_t i = 0; i < words.size(); i++) {
            if (i > 0) cout << ", ";
            cout << "\"" << words[i] << "\"";
        }
        cout << "] (å…±" << words.size() << "ä¸ªè¯)\n";
    }

    // åŠ è½½ç´¢å¼•å¹¶æ£€æŸ¥
    cout << "\n=== ç´¢å¼•æ£€æŸ¥ ===\n";
    auto index = make_shared<InvertIndex>();
    index->load(config->get("index_path"));

    // æ£€æŸ¥è¿™äº›è¯åœ¨ç´¢å¼•ä¸­æ˜¯å¦å­˜åœ¨
    cout << "\nç›´æ¥åœ¨ç´¢å¼•ä¸­æŸ¥æ‰¾è¿™äº›è¯...\n";
    for (const auto& query : testQueries) {
        auto results = index->search({query}, 5);
        cout << "ç›´æ¥æœç´¢ \"" << query << "\": æ‰¾åˆ° " << results.size() << " ä¸ªç»“æœ\n";
    }

    // ä½¿ç”¨åˆ†è¯åå†æœç´¢
    cout << "\nåˆ†è¯åæœç´¢...\n";
    for (const auto& query : testQueries) {
        auto words = splitTool->cut(query);
        auto results = index->search(words, 5);
        cout << "åˆ†è¯æœç´¢ \"" << query << "\": åˆ†è¯ä¸º " << words.size()
             << " ä¸ªè¯, æ‰¾åˆ° " << results.size() << " ä¸ªç»“æœ\n";
    }

    return 0;
}

================================================================================
File: Configuration.cc
Path: src\Configuration.cc
Type: cpp
================================================================================
#include "Configuration.h"
#include <fstream>
#include <iostream>

using std::ifstream;
using std::cout;

Configuration* Configuration::_pInstance = nullptr;

Configuration* Configuration::getInstance() {
    if (_pInstance == nullptr) {
        _pInstance = new Configuration();
    }
    return _pInstance;
}

void Configuration::load(const string& configPath) {
    ifstream ifs(configPath);
    if (!ifs) {
        cout << "Error: Cannot open config file: " << configPath << "\n";
        return;
    }

    string line;
    while (std::getline(ifs, line)) {
        // è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if (line.empty() || line[0] == '#') {
            continue;
        }

        // è§£æ key = value
        size_t pos = line.find('=');
        if (pos != string::npos) {
            string key = line.substr(0, pos);
            string value = line.substr(pos + 1);

            // å»é™¤é¦–å°¾ç©ºæ ¼
            auto trim = [](string& s) {
                size_t start = s.find_first_not_of(" \t");
                size_t end = s.find_last_not_of(" \t");
                if (start != string::npos && end != string::npos) {
                    s = s.substr(start, end - start + 1);
                }
            };

            trim(key);
            trim(value);
            _configs[key] = value;
        }
    }
    cout << "Loaded " << _configs.size() << " config items\n";
}

string Configuration::get(const string& key) const {
    auto it = _configs.find(key);
    if (it != _configs.end()) {
        return it->second;
    }
    return "";
}

================================================================================
File: DictProducer.cc
Path: src\DictProducer.cc
Type: cpp
================================================================================
#include "DictProducer.h"
#include "SplitTool.h"
#include "WebPage.h"
#include <fstream>
#include <sstream>
#include <iostream>
#include <algorithm>

using std::ifstream;
using std::ofstream;
using std::cout;
using std::getline;

DictProducer::DictProducer(SplitTool* splitTool)
    : _splitTool(splitTool) {
}

void DictProducer::build(const vector<shared_ptr<WebPage>>& pages) {
    // ä»ç½‘é¡µåº“æ„å»ºè¯å…¸
    for (const auto& page : pages) {
        auto& wordsMap = page->getWordsMap();
        for (const auto& pair : wordsMap) {
            _dict[pair.first] += pair.second;
        }
    }

    cout << "Built dictionary with " << _dict.size() << " words\n";

    // æ„å»ºå­—ç¬¦ç´¢å¼•
    buildIndex();
}

void DictProducer::buildFromFile(const string& filePath) {
    ifstream ifs(filePath);
    if (!ifs) {
        cout << "Error: Cannot open file: " << filePath << "\n";
        return;
    }

    string line;
    while (getline(ifs, line)) {
        if (line.empty()) continue;

        // åˆ†è¯
        vector<string> words = _splitTool->cut(line);
        for (const auto& word : words) {
            _dict[word]++;
        }
    }

    cout << "Built dictionary with " << _dict.size() << " words\n";

    // æ„å»ºå­—ç¬¦ç´¢å¼•
    buildIndex();
}

void DictProducer::buildIndex() {
    // ä¸ºæ¯ä¸ªè¯å»ºç«‹å­—ç¬¦ç´¢å¼•
    for (const auto& pair : _dict) {
        const string& word = pair.first;
        vector<string> chars = extractChars(word);

        for (const auto& ch : chars) {
            _charIndex[ch].insert(word);
        }
    }

    cout << "Built character index with " << _charIndex.size() << " characters\n";
}

bool DictProducer::isChinese(const string& ch) const {
    // UTF-8 ä¸­æ–‡å­—ç¬¦é€šå¸¸æ˜¯ 3 å­—èŠ‚
    if (ch.length() != 3) return false;

    unsigned char c0 = ch[0];
    unsigned char c1 = ch[1];
    unsigned char c2 = ch[2];

    // ä¸­æ–‡ UTF-8 èŒƒå›´ï¼š0xE4-0xE9 å¼€å¤´
    return (c0 >= 0xE4 && c0 <= 0xE9) &&
           (c1 >= 0x80 && c1 <= 0xBF) &&
           (c2 >= 0x80 && c2 <= 0xBF);
}

vector<string> DictProducer::extractChars(const string& word) const {
    vector<string> chars;
    size_t i = 0;

    while (i < word.length()) {
        unsigned char c = word[i];
        size_t charLen = 1;

        // æ ¹æ® UTF-8 ç¼–ç ç¡®å®šå­—ç¬¦é•¿åº¦
        if ((c & 0x80) == 0) {
            charLen = 1;  // ASCII
        } else if ((c & 0xE0) == 0xC0) {
            charLen = 2;
        } else if ((c & 0xF0) == 0xE0) {
            charLen = 3;  // ä¸­æ–‡é€šå¸¸æ˜¯ 3 å­—èŠ‚
        } else if ((c & 0xF8) == 0xF0) {
            charLen = 4;
        }

        if (i + charLen <= word.length()) {
            chars.push_back(word.substr(i, charLen));
        }
        i += charLen;
    }

    return chars;
}

vector<string> DictProducer::getCandidates(const string& prefix) const {
    vector<string> candidates;

    // æå–å‰ç¼€çš„æ‰€æœ‰å­—ç¬¦
    vector<string> chars = extractChars(prefix);
    if (chars.empty()) return candidates;

    // è·å–åŒ…å«ç¬¬ä¸€ä¸ªå­—ç¬¦çš„æ‰€æœ‰è¯
    auto it = _charIndex.find(chars[0]);
    if (it == _charIndex.end()) return candidates;

    // ç­›é€‰åŒ…å«æ‰€æœ‰å­—ç¬¦çš„è¯
    for (const auto& word : it->second) {
        bool match = true;
        for (size_t i = 1; i < chars.size() && match; ++i) {
            if (word.find(chars[i]) == string::npos) {
                match = false;
            }
        }
        if (match) {
            candidates.push_back(word);
        }
    }

    // æŒ‰è¯é¢‘æ’åºï¼ˆè¯é¢‘é«˜çš„åœ¨å‰ï¼‰
    std::sort(candidates.begin(), candidates.end(),
              [this](const string& a, const string& b) {
                  auto itA = _dict.find(a);
                  auto itB = _dict.find(b);
                  int freqA = (itA != _dict.end()) ? itA->second : 0;
                  int freqB = (itB != _dict.end()) ? itB->second : 0;
                  return freqA > freqB;
              });

    return candidates;
}

void DictProducer::storeDict(const string& filePath) {
    ofstream ofs(filePath);
    if (!ofs) {
        cout << "Error: Cannot create dict file: " << filePath << "\n";
        return;
    }

    // æŒ‰è¯é¢‘æ’åºåå­˜å‚¨
    vector<std::pair<string, int>> sortedDict(_dict.begin(), _dict.end());
    std::sort(sortedDict.begin(), sortedDict.end(),
              [](const auto& a, const auto& b) {
                  return a.second > b.second;
              });

    for (const auto& pair : sortedDict) {
        ofs << pair.first << " " << pair.second << "\n";
    }

    cout << "Stored dictionary to " << filePath << "\n";
}

void DictProducer::storeIndex(const string& filePath) {
    ofstream ofs(filePath);
    if (!ofs) {
        cout << "Error: Cannot create index file: " << filePath << "\n";
        return;
    }

    for (const auto& pair : _charIndex) {
        ofs << pair.first;
        for (const auto& word : pair.second) {
            ofs << " " << word;
        }
        ofs << "\n";
    }

    cout << "Stored index to " << filePath << "\n";
}

void DictProducer::loadDict(const string& filePath) {
    ifstream ifs(filePath);
    if (!ifs) {
        cout << "Error: Cannot open dict file: " << filePath << "\n";
        return;
    }

    _dict.clear();
    string line;
    while (getline(ifs, line)) {
        std::istringstream iss(line);
        string word;
        int freq;
        if (iss >> word >> freq) {
            _dict[word] = freq;
        }
    }

    cout << "Loaded dictionary with " << _dict.size() << " words\n";
}

void DictProducer::loadIndex(const string& filePath) {
    ifstream ifs(filePath);
    if (!ifs) {
        cout << "Error: Cannot open index file: " << filePath << "\n";
        return;
    }

    _charIndex.clear();
    string line;
    while (getline(ifs, line)) {
        std::istringstream iss(line);
        string ch;
        iss >> ch;

        string word;
        while (iss >> word) {
            _charIndex[ch].insert(word);
        }
    }

    cout << "Loaded index with " << _charIndex.size() << " characters\n";
}

================================================================================
File: InvertIndex.cc
Path: src\InvertIndex.cc
Type: cpp
================================================================================
#include "InvertIndex.h"
#include "WebPage.h"
#include <fstream>
#include <sstream>
#include <cmath>
#include <algorithm>
#include <iostream>
#include <chrono> // ç”¨äºè®¡æ—¶è°ƒè¯•

using std::ifstream;
using std::ofstream;
using std::stringstream;
using std::cout;
using std::log;
using std::sort;
using std::partial_sort; // ä¼˜åŒ–: å¼•å…¥å±€éƒ¨æ’åº

InvertIndex::InvertIndex()
    : _totalDocs(0)
    , _avgDocLen(0) {
}

void InvertIndex::build(vector<shared_ptr<WebPage>>& pages) {
    _totalDocs = pages.size();
    if (_totalDocs == 0) {
        cout << "Warning: No pages to build index\n";
        return;
    }

    // ç¬¬ä¸€æ­¥ï¼šç»Ÿè®¡ DF (Document Frequency)
    // ä¼˜åŒ–: ä½¿ç”¨ unordered_map åŠ é€Ÿæ„å»ºè¿‡ç¨‹
    unordered_map<string, int> docFreq;//è¯é¢‘ï¼Œè¯¥è¯å‡ºç°åœ¨ä¸åŒæ–‡æ¡£çš„ä¸ªæ•°
    long long totalLen = 0;//æ‰€æœ‰æ–‡ä»¶çš„é•¿åº¦

    for (const auto& page : pages) {
        auto& wordsMap = page->getWordsMap();
        int docLen = 0;//åªåœ¨éå†è¿‡ç¨‹è®¡ç®—å½“å‰æ–‡æ¡£é•¿åº¦ï¼Œç”¨äºæ±‚å’Œæ‰€æœ‰æ–‡æ¡£æ€»é•¿
        for (const auto& pair : wordsMap) {
            docLen += pair.second;
            docFreq[pair.first]++;
        }
        _docLens[page->getDocId()] = docLen;
        totalLen += docLen;
    }

    _avgDocLen = (double)totalLen / _totalDocs;//å¹³å‡æ–‡ä»¶é•¿åº¦
    cout << "Average document length: " << _avgDocLen << "\n";

    // ç¬¬äºŒæ­¥ï¼šæ„å»ºå€’æ’ç´¢å¼•
    for (const auto& page : pages) {
        auto& wordsMap = page->getWordsMap();
        int docId = page->getDocId();
        int docLen = _docLens[docId];

        for (const auto& pair : wordsMap) {
            const string& word = pair.first;
            int termFreq = pair.second;

            // ä¼˜åŒ–: é¢„è®¡ç®—æƒé‡ï¼Œè¿è¡Œæ—¶åªåšåŠ æ³•
            double weight = calculateBM25(termFreq, docLen, docFreq[word]);

            InvertIndexItem item;
            item.docId = docId;
            item.weight = weight;
            item.termFreq = termFreq;

            _invertIndex[word].push_back(item);
        }
    }

    // å¯¹æ¯ä¸ªè¯çš„å€’æ’åˆ—è¡¨æ’åºï¼ˆç¦»çº¿åšä¸€æ¬¡ï¼Œåœ¨çº¿ä¸ç”¨åšï¼‰
    // ä¿æŒæŒ‰ docId æ’åºæˆ–æƒé‡æ’åºå‡å¯ï¼Œè¿™é‡Œä¿æŒåŸé€»è¾‘æŒ‰æƒé‡æ’åº
    for (auto& pair : _invertIndex) {
        sort(pair.second.begin(), pair.second.end(),
             [](const InvertIndexItem& a, const InvertIndexItem& b) {
                 return a.weight > b.weight;
             });
    }

    cout << "Built inverted index with " << _invertIndex.size() << " terms (BM25)\n";
}
//docFreq åŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°ã€‚ totalDocs æ–‡æ¡£æ€»æ•°ã€‚
double InvertIndex::calculateIDF(int docFreq, int totalDocs) {
    if (docFreq == 0) return 0;
    double idf = log((totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1.0);
    return idf > 0 ? idf : 0;
}


//åœ¨è¯¥æ–‡æ¡£è¯é¢‘   æ–‡æ¡£é•¿åº¦     è¯¥è¯å‡ºç°åœ¨ä¸åŒæ–‡æ¡£ä¸ªæ•°
double InvertIndex::calculateBM25(int termFreq, int docLen, int docFreq) {
    double idf = calculateIDF(docFreq, _totalDocs);
    double tfNorm = (termFreq * (K1 + 1)) /
                    (termFreq + K1 * (1 - B + B * (docLen / _avgDocLen)));
    return idf * tfNorm;
}


vector<pair<int, double>> InvertIndex::search(const vector<string>& queryWords, int topK) {
    if (queryWords.empty()) return {};

    // ä¼˜åŒ– 1: ä½¿ç”¨ vector ä»£æ›¿ map è¿›è¡Œåˆ†æ•°ç»Ÿè®¡
    // å‡è®¾ docId æ˜¯è¿ç»­çš„ä¸”æœ€å¤§ä¸º _totalDocs + 100 (å†—ä½™ç©ºé—´)
    // è¿™ç§æ–¹å¼è®¿é—®é€Ÿåº¦æ˜¯ O(1)ï¼Œä¸”å†…å­˜è¿ç»­ï¼Œå¯¹ CPU Cache æå…¶å‹å¥½
    // æ³¨æ„ï¼šéœ€è¦ç¡®ä¿ docId ä¸ä¼šè¶Šç•Œï¼Œè¿™é‡Œå– _docLens ä¸­æœ€å¤§çš„ key æ¯”è¾ƒå®‰å…¨
    // ç®€å•èµ·è§ï¼Œå¦‚æœ docId æ˜¯ 1~Nï¼Œvector å¤§å°è®¾ä¸º _totalDocs + 1 å³å¯
    int maxDocId = _docLens.empty() ? 0 : _docLens.rbegin()->first;
    
    vector<double> scores(maxDocId + 1, 0.0);//ç”¨æ¥ç»Ÿè®¡æ¯ä¸ªæ–‡æ¡£çš„å¾—åˆ†
    
    // ç”¨äºè®°å½•å“ªäº› docId è¢«æ›´æ–°äº†ï¼Œé¿å…æœ€åéå†æ•´ä¸ª scores æ•°ç»„
    vector<int> dirtyDocIds; 

    for (const auto& word : queryWords) {
        auto it = _invertIndex.find(word); // unordered_map æŸ¥æ‰¾ O(1)
        if (it != _invertIndex.end()) {
            for (const auto& item : it->second) {
                if (scores[item.docId] == 0.0) {
                    dirtyDocIds.push_back(item.docId);
                }
                scores[item.docId] += item.weight;
            }
        }
    }

    // æ”¶é›†ç»“æœ
    vector<pair<int, double>> results;
    results.reserve(dirtyDocIds.size());
    for (int docId : dirtyDocIds) {
        results.emplace_back(docId, scores[docId]);
    }

    // ä¼˜åŒ– 2: ä½¿ç”¨ partial_sort ä»…å¯¹å‰ TopK è¿›è¡Œæ’åº
    // æ—¶é—´å¤æ‚åº¦ä» O(N log N) é™ä½åˆ° O(N log K)
    if (results.size() > (size_t)topK) {
        partial_sort(results.begin(), 
                     results.begin() + topK, 
                     results.end(),
                     [](const pair<int, double>& a, const pair<int, double>& b) {
                         return a.second > b.second; // é™åº
                     });
        results.resize(topK);
    } else {
        sort(results.begin(), results.end(),
             [](const pair<int, double>& a, const pair<int, double>& b) {
                 return a.second > b.second;
             });
    }

    return results;
}

void InvertIndex::store(const string& filePath) {
    ofstream ofs(filePath);
    if (!ofs) {
        cout << "Error: Cannot create index file: " << filePath << "\n";
        return;
    }

    ofs << "#META " << _totalDocs << " " << _avgDocLen << "\n";
    ofs << "#DOCLENS";
    for (const auto& pair : _docLens) {
        ofs << " " << pair.first << ":" << pair.second;
    }
    ofs << "\n";

    for (const auto& pair : _invertIndex) {
        ofs << pair.first;
        for (const auto& item : pair.second) {
            ofs << " " << item.docId << ":" << item.weight << ":" << item.termFreq;
        }
        ofs << "\n";
    }
    cout << "Stored index to " << filePath << "\n";
}

// ä¼˜åŒ–ï¼šLoad å‡½æ•°ï¼Œå»é™¤ stringstream
void InvertIndex::load(const string& filePath) {
    ifstream ifs(filePath);
    if (!ifs) {
        cout << "Error: Cannot open index file: " << filePath << "\n";
        return;
    }

    _invertIndex.clear();
    _docLens.clear();
    string line;

    while (std::getline(ifs, line)) {
        if (line.empty()) continue;

        if (line.size() >= 5 &&line.compare(0, 5, "#META") == 0) {
            stringstream ss(line.substr(6));
            ss >> _totalDocs >> _avgDocLen;
        } else if (line.compare(0, 8, "#DOCLENS") == 0) {
            stringstream ss(line.substr(9));
            string item;
            while (ss >> item) {
                size_t pos = item.find(':');
                if (pos != string::npos) {
                    int docId = std::stoi(item.substr(0, pos));
                    int docLen = std::stoi(item.substr(pos + 1));
                    _docLens[docId] = docLen;
                }
            }
        } else {
            // æ‰‹åŠ¨è§£æå€’æ’åˆ—è¡¨è¡Œï¼šword docId:weight:freq docId:weight:freq ...
            // ç›¸æ¯” stringstreamï¼Œç›´æ¥æŸ¥æ‰¾ç©ºæ ¼åˆ†å‰²æ•ˆç‡æ›´é«˜
            size_t firstSpace = line.find(' ');
            if (firstSpace == string::npos) continue;

            string word = line.substr(0, firstSpace);
            
            size_t curPos = firstSpace + 1;
            while (curPos < line.size()) {
                size_t nextSpace = line.find(' ', curPos);
                size_t itemLen = (nextSpace == string::npos) ? (line.size() - curPos) : (nextSpace - curPos);
                
                // è§£æ item å­—ç¬¦ä¸²: "docId:weight:termFreq"
                string itemStr = line.substr(curPos, itemLen);
                
                size_t p1 = itemStr.find(':');
                size_t p2 = itemStr.find(':', p1 + 1);
                
                if (p1 != string::npos && p2 != string::npos) {
                    InvertIndexItem idxItem;
                    idxItem.docId = std::stoi(itemStr.substr(0, p1));
                    idxItem.weight = std::stod(itemStr.substr(p1 + 1, p2 - p1 - 1));
                    idxItem.termFreq = std::stoi(itemStr.substr(p2 + 1));
                    _invertIndex[word].push_back(idxItem);
                }

                if (nextSpace == string::npos) break;
                curPos = nextSpace + 1;
            }
        }
    }

    cout << "Loaded index with " << _invertIndex.size() << " terms (BM25)\n";
}

================================================================================
File: KeywordRecommender.cc
Path: src\KeywordRecommender.cc
Type: cpp
================================================================================
#include "KeywordRecommender.h"
#include "DictProducer.h"
#include <algorithm>
#include <iostream>

using std::min;
using std::cout;

KeywordRecommender::KeywordRecommender(const DictProducer* dictProducer)
    : _dictProducer(dictProducer) {
}

vector<string> KeywordRecommender::splitToChars(const string& s) {
    vector<string> chars;
    size_t i = 0;

    while (i < s.length()) {
        unsigned char c = s[i];
        size_t charLen = 1;

        // æ ¹æ® UTF-8 ç¼–ç ç¡®å®šå­—ç¬¦é•¿åº¦
        if ((c & 0x80) == 0) {
            charLen = 1;  // ASCII
        } else if ((c & 0xE0) == 0xC0) {
            charLen = 2;
        } else if ((c & 0xF0) == 0xE0) {
            charLen = 3;  // ä¸­æ–‡é€šå¸¸æ˜¯ 3 å­—èŠ‚
        } else if ((c & 0xF8) == 0xF0) {
            charLen = 4;
        }

        if (i + charLen <= s.length()) {
            chars.push_back(s.substr(i, charLen));
        }
        i += charLen;
    }

    return chars;
}

int KeywordRecommender::editDistance(const string& s1, const string& s2) {
    // ä½¿ç”¨åŠ¨æ€è§„åˆ’è®¡ç®—æœ€å°ç¼–è¾‘è·ç¦»
    // æ”¯æŒ UTF-8 ä¸­æ–‡å­—ç¬¦

    vector<string> chars1 = splitToChars(s1);
    vector<string> chars2 = splitToChars(s2);

    int m = chars1.size();
    int n = chars2.size();

    // dp[i][j] è¡¨ç¤º chars1[0..i-1] å’Œ chars2[0..j-1] çš„ç¼–è¾‘è·ç¦»
    vector<vector<int>> dp(m + 1, vector<int>(n + 1, 0));

    // åˆå§‹åŒ–è¾¹ç•Œ
    for (int i = 0; i <= m; ++i) dp[i][0] = i;
    for (int j = 0; j <= n; ++j) dp[0][j] = j;
    //è¡¨ç¤ºä»æºç åˆ°ç›®æ ‡ç éœ€è¦çš„æ“ä½œæ­¥éª¤æ•°ï¼Œç«–å‘ä¸ºæºç ï¼Œæ¨ªå‘ä¸ºç›®æ ‡ç 
    // åŠ¨æ€è§„åˆ’å¡«è¡¨
    for (int i = 1; i <= m; ++i) {
        for (int j = 1; j <= n; ++j) {
            if (chars1[i - 1] == chars2[j - 1]) {
                dp[i][j] = dp[i - 1][j - 1];  // å­—ç¬¦ç›¸åŒï¼Œæ— éœ€æ“ä½œ
            } else {
                dp[i][j] = 1 + min({
                    dp[i - 1][j],      // åˆ é™¤ ï¼ˆå‘ä¸Šï¼‰
                    dp[i][j - 1],      // æ’å…¥ ï¼ˆå‘å·¦ï¼‰
                    dp[i - 1][j - 1]   // æ›¿æ¢ ï¼ˆå‘åä¸Šï¼‰
                });
            }
        }
    }

    return dp[m][n];
}

vector<string> KeywordRecommender::recommend(const string& query, int topK, int maxDistance) {
    vector<string> results;

    // 1. é˜²å¾¡æ€§ç¼–ç¨‹ï¼šç©ºæŒ‡é’ˆæ£€æŸ¥
    if (!_dictProducer) {
        return results;
    }

    // 2. ğŸ”´ æ€§èƒ½æ ¸å¿ƒä¼˜åŒ–ï¼šLoop Hoisting (å¾ªç¯å¤–æ)
    // Query çš„åˆ‡åˆ†æ˜¯ä¸å˜é‡ï¼Œç§»åˆ°å¾ªç¯å¤–ã€‚
    // åŸä»£ç åœ¨å¾ªç¯å†…åˆ‡åˆ†ï¼Œè‹¥è¯å…¸æœ‰ 10w è¯ï¼Œå°±æµªè´¹äº† 10w æ¬¡åˆ†é…ã€‚
    vector<string> queryChars = splitToChars(query); 
    
    // ä¼˜å…ˆé˜Ÿåˆ—ï¼šå­˜å‚¨å€™é€‰è¯
    priority_queue<CandidateWord> pq;

    // è·å–è¯å…¸å¼•ç”¨
    const auto& dict = _dictProducer->getDict();

    // 3. éå†è¯å…¸
    for (const auto& pair : dict) {
        const string& word = pair.first;
        int freq = pair.second;

        // 4. è·å–è¯çš„å­—ç¬¦å‘é‡
        vector<string> wordChars = splitToChars(word);

        // 5. é•¿åº¦å¯å‘å¼è¿‡æ»¤ (Heuristic Pruning)
        int distDiff = (int)queryChars.size() - (int)wordChars.size();
        if (std::abs(distDiff) > maxDistance) {
            continue;
        }

        // 6. è®¡ç®—ç¼–è¾‘è·ç¦»
        int dist = editDistance(query, word);

        if (dist <= maxDistance) {
            CandidateWord candidate;
            candidate.word = word;
            candidate.distance = dist;
            candidate.frequency = freq;
            pq.push(candidate);
            
            // 7. å†…å­˜ä¼˜åŒ–ç‚¹ï¼ˆè¿›é˜¶ï¼‰ï¼š
            // å¦‚æœ pq çš„å¤§å°å·²ç»è¿œè¿œè¶…è¿‡ topKï¼ˆæ¯”å¦‚ > 2*topKï¼‰ï¼Œ
            // ä¸”å½“å‰å †é¡¶å…ƒç´ çš„â€œåŠ£è´¨ç¨‹åº¦â€å·²ç»å¾ˆé«˜ï¼Œå¯ä»¥è€ƒè™‘ pop() æ‰æœ€å·®çš„ï¼Œ
            // ä¿æŒå †åœ¨ä¸€ä¸ªåˆç†å¤§å°ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸ã€‚
            // (æ³¨ï¼šè¿™å–å†³äº CandidateWord çš„ operator< å®šä¹‰ï¼Œæ­¤å¤„æš‚æŒ‰åŸé€»è¾‘ä¿ç•™)
        }
    }

    // 8. å–å‡ºç»“æœ
    while (!pq.empty() && (int)results.size() < topK) {
        results.push_back(pq.top().word);
        pq.pop();
    }

    return results;
}

================================================================================
File: PageLib.cc
Path: src\PageLib.cc
Type: cpp
================================================================================
#include "PageLib.h"
#include "WebPage.h"
#include <fstream>
#include <sstream>
#include <iostream>
#include <dirent.h>
#include <sys/stat.h>

using std::ifstream;
using std::ofstream;
using std::stringstream;
using std::cout;
using std::make_shared;

PageLib::PageLib(const string& dataPath, SplitTool* splitTool)
    : _dataPath(dataPath)
    , _splitTool(splitTool) {
}

void PageLib::load() {
    // éå†æ•°æ®ç›®å½•ï¼ŒåŠ è½½æ‰€æœ‰æ–‡ä»¶
    DIR* dir = opendir(_dataPath.c_str());
    if (!dir) {
        cout << "Error: Cannot open data directory: " << _dataPath << "\n";
        return;
    }

    struct dirent* entry;
    while ((entry = readdir(dir)) != nullptr) {
        string filename = entry->d_name;
        if (filename == "." || filename == "..") {
            continue;
        }

        string filepath = _dataPath + "/" + filename;
        struct stat st;
        if (stat(filepath.c_str(), &st) == 0 && S_ISREG(st.st_mode) && filename.find(".xml") != string::npos) {
            parseFile(filepath);
        }
    }
    closedir(dir);

    cout << "Loaded " << _pages.size() << " pages\n";
}

void PageLib::parseFile(const string& filePath) {
    ifstream ifs(filePath);
    if (!ifs) {
        cout << "Warning: Cannot open file: " << filePath << "\n";
        return;
    }

    stringstream ss;
    ss << ifs.rdbuf();
    string content = ss.str();

    // å‡è®¾æ–‡ä»¶ä¸­å¤šä¸ªæ–‡æ¡£ç”¨ <doc>...</doc> åˆ†éš”
    size_t pos = 0;
    string docStart = "<doc>";
    string docEnd = "</doc>";

    while ((pos = content.find(docStart, pos)) != string::npos) {
        size_t endPos = content.find(docEnd, pos);
        if (endPos == string::npos) {
            break;
        }

        string doc = content.substr(pos, endPos - pos + docEnd.length());
        auto page = make_shared<WebPage>(doc, _splitTool);
        _pages.push_back(page);

        pos = endPos + docEnd.length();
    }

    // å¦‚æœæ²¡æœ‰ <doc> æ ‡ç­¾ï¼ŒæŠŠæ•´ä¸ªæ–‡ä»¶å½“ä½œä¸€ä¸ªæ–‡æ¡£
    if (_pages.empty() && !content.empty()) {
        auto page = make_shared<WebPage>(content, _splitTool);
        _pages.push_back(page);
    }
}

void PageLib::store(const string& outputPath) {
    ofstream ofs(outputPath);
    if (!ofs) {
        cout << "Error: Cannot create output file: " << outputPath << "\n";
        return;
    }

    for (const auto& page : _pages) {
        ofs << "<doc>\n";
        ofs << "<docid>" << page->getDocId() << "</docid>\n";
        ofs << "<title>" << page->getTitle() << "</title>\n";
        ofs << "<url>" << page->getUrl() << "</url>\n";
        ofs << "<content>" << page->getContent() << "</content>\n";
        ofs << "</doc>\n\n";
    }

    cout << "Stored " << _pages.size() << " pages to " << outputPath << "\n";
}

void PageLib::storeSeparated(const string& metaPath, const string& contentPath) {
    // 1. å†™å…¥å†…å®¹æ–‡ä»¶ï¼ˆäºŒè¿›åˆ¶ï¼‰
    ofstream contentOfs(contentPath, std::ios::binary);
    if (!contentOfs) {
        cout << "Error: Cannot create content file: " << contentPath << "\n";
        return;
    }

    // 2. å†™å…¥å…ƒæ•°æ®æ–‡ä»¶
    ofstream metaOfs(metaPath);
    if (!metaOfs) {
        cout << "Error: Cannot create meta file: " << metaPath << "\n";
        return;
    }

    metaOfs << "#FORMAT docId|title|url|offset|length\n";

    size_t currentOffset = 0;
    for (const auto& page : _pages) {
        string content = page->getContent();
        size_t contentLen = content.length();

        // å†™å…¥å†…å®¹
        contentOfs.write(content.c_str(), contentLen);

        // å†™å…¥å…ƒæ•°æ®ï¼ˆä½¿ç”¨ | åˆ†éš”ï¼Œé¿å…æ ‡é¢˜ä¸­çš„ç©ºæ ¼é—®é¢˜ï¼‰
        metaOfs << page->getDocId() << "|"
                << page->getTitle() << "|"
                << page->getUrl() << "|"
                << currentOffset << "|"
                << contentLen << "\n";

        currentOffset += contentLen;
    }

    cout << "Stored " << _pages.size() << " pages (separated format)\n";
    cout << "  Meta: " << metaPath << "\n";
    cout << "  Content: " << contentPath << " (" << currentOffset << " bytes)\n";
}

unordered_map<int, WebPageMeta> PageLib::loadMeta(const string& metaPath) {
    unordered_map<int, WebPageMeta> result;

    ifstream ifs(metaPath);
    if (!ifs) {
        cout << "Error: Cannot open meta file: " << metaPath << "\n";
        return result;
    }

    string line;
    while (std::getline(ifs, line)) {
        if (line.empty() || line[0] == '#') continue;

        // è§£æï¼šdocId|title|url|offset|length
        size_t p1 = line.find('|');
        size_t p2 = line.find('|', p1 + 1);
        size_t p3 = line.find('|', p2 + 1);
        size_t p4 = line.find('|', p3 + 1);

        if (p1 == string::npos || p2 == string::npos ||
            p3 == string::npos || p4 == string::npos) {
            continue;
        }

        WebPageMeta meta;
        meta.docId = std::stoi(line.substr(0, p1));
        meta.title = line.substr(p1 + 1, p2 - p1 - 1);
        meta.url = line.substr(p2 + 1, p3 - p2 - 1);
        meta.contentOffset = std::stoull(line.substr(p3 + 1, p4 - p3 - 1));
        meta.contentLength = std::stoull(line.substr(p4 + 1));

        result[meta.docId] = meta;
    }

    cout << "Loaded " << result.size() << " page metadata entries\n";
    return result;
}

================================================================================
File: PageLibPreprocessor.cc
Path: src\PageLibPreprocessor.cc
Type: cpp
================================================================================
#include "PageLibPreprocessor.h"
#include "WebPage.h"
#include <algorithm>
#include <cmath>
#include <iostream>

using std::cout;
using std::make_shared;

PageLibPreprocessor::PageLibPreprocessor(vector<shared_ptr<WebPage>>& pages, SplitTool* splitTool)
    : _pages(pages)
    , _splitTool(splitTool) {
}

void PageLibPreprocessor::deduplicate() {
    // åŸºäº SimHash å»é‡
    vector<uint64_t> hashes;

    for (const auto& page : _pages) {
        uint64_t hash = page->getSimhash();
        bool isDuplicate = false;

        for (const auto& existingHash : hashes) {
            if (isSimilar(hash, existingHash)) {
                isDuplicate = true;
                break;
            }
        }

        if (!isDuplicate) {
            _processedPages.push_back(page);
            hashes.push_back(hash);
        }
    }

    cout << "Deduplication: " << _pages.size() << " -> " << _processedPages.size() << " pages\n";
}

bool PageLibPreprocessor::isSimilar(uint64_t hash1, uint64_t hash2, int threshold) {
    // è®¡ç®—æ±‰æ˜è·ç¦»
    uint64_t diff = hash1 ^ hash2;
    int distance = 0;

    while (diff) {
        distance += diff & 1;
        diff >>= 1;
    }

    return distance < threshold;
}


================================================================================
File: SearchServer.cc
Path: src\SearchServer.cc
Type: cpp
================================================================================
#include "SearchServer.h"
#include "InvertIndex.h"
#include "SplitTool.h"
#include "WebPage.h"
#include "DictProducer.h"
#include "KeywordRecommender.h"
#include "wfrest/HttpServer.h"
#include "wfrest/json.hpp"
#include <iostream>
#include <sstream>
#include <iomanip>

using std::cout;

// URL è§£ç å‡½æ•°
static string urlDecode(const string& encoded) {
    string decoded;
    decoded.reserve(encoded.size());

    for (size_t i = 0; i < encoded.size(); ++i) {
        if (encoded[i] == '%' && i + 2 < encoded.size()) {
            int hex = 0;
            std::istringstream iss(encoded.substr(i + 1, 2));
            if (iss >> std::hex >> hex) {
                decoded += static_cast<char>(hex);
                i += 2;
            } else {
                decoded += encoded[i];
            }
        } else if (encoded[i] == '+') {
            decoded += ' ';
        } else {
            decoded += encoded[i];
        }
    }
    return decoded;
}

using wfrest::HttpServer;
using wfrest::HttpReq;
using wfrest::HttpResp;
using nlohmann::json;

SearchServer::SearchServer(const string& ip, int port,
                           shared_ptr<InvertIndex> index,
                           SplitTool* splitTool)
    : _ip(ip)
    , _port(port)
    , _index(index)
    , _splitTool(splitTool)
    , _cache(std::make_shared<SearchCache>(1000)) {  // é»˜è®¤ç¼“å­˜1000æ¡
}

void SearchServer::setPageLib(const map<int, shared_ptr<WebPage>>& pageLib) {
    _pageLib = pageLib;
    _useLiteMode = false;
}

void SearchServer::setPageLibLite(const unordered_map<int, WebPageMeta>& pageMeta,
                                   const string& contentFilePath) {
    _pageMetaLib = pageMeta;
    _contentStore = std::make_shared<ContentStore>(contentFilePath);
    _useLiteMode = true;
}

void SearchServer::setDictProducer(shared_ptr<DictProducer> dictProducer) {
    _dictProducer = dictProducer;
}

void SearchServer::setRecommender(shared_ptr<KeywordRecommender> recommender) {
    _recommender = recommender;
}

void SearchServer::setCacheCapacity(size_t capacity) {
    _cache = std::make_shared<SearchCache>(capacity);
}

void SearchServer::start() {
    HttpServer server;

    // æœç´¢æ¥å£
    server.GET("/search", [this](const HttpReq* req, HttpResp* resp) {
        string query = req->query("q");
        if (query.empty()) {
            json error;
            error["error"] = "Missing query parameter 'q'";
            resp->set_header_pair("Content-Type", "application/json; charset=utf-8");
            resp->String(error.dump());
            return;
        }
        query = urlDecode(query);  // URL è§£ç 
        string result = handleSearch(query);
        resp->set_header_pair("Content-Type", "application/json; charset=utf-8");
        resp->set_header_pair("Access-Control-Allow-Origin", "*");
        resp->String(result);
    });

    // å…³é”®è¯æ¨èæ¥å£
    server.GET("/suggest", [this](const HttpReq* req, HttpResp* resp) {
        string query = req->query("q");
        if (query.empty()) {
            json error;
            error["error"] = "Missing query parameter 'q'";
            resp->set_header_pair("Content-Type", "application/json; charset=utf-8");
            resp->String(error.dump());
            return;
        }
        query = urlDecode(query);  // URL è§£ç 
        string result = handleSuggest(query);
        resp->set_header_pair("Content-Type", "application/json; charset=utf-8");
        resp->set_header_pair("Access-Control-Allow-Origin", "*");
        resp->String(result);
    });

    // å¥åº·æ£€æŸ¥
    server.GET("/health", [this](const HttpReq* req, HttpResp* resp) {
        json health;
        health["status"] = "ok";
        health["cache_size"] = _cache->size();
        health["cache_hit_rate"] = _cache->hitRate();
        resp->set_header_pair("Content-Type", "application/json; charset=utf-8");
        resp->String(health.dump());
    });

    // é™æ€æ–‡ä»¶ï¼ˆæœç´¢é¡µé¢ï¼‰
    server.GET("/", [](const HttpReq* req, HttpResp* resp) {
        resp->File("static/index.html");
    });

    // é™æ€èµ„æº
    server.GET("/static/*", [](const HttpReq* req, HttpResp* resp) {
        string path = req->match_path();
        resp->File(path.substr(1));  // å»æ‰å‰å¯¼ /
    });

    cout << "Search server starting on " << _ip << ":" << _port << "\n";
    cout << "Cache capacity: " << 1000 << " entries\n";
    cout << "Press Ctrl+C to stop the server\n";

    if (server.start(_port) == 0) {
        server.list_routes();
        _running = true;

        // ä½¿ç”¨æ¡ä»¶å˜é‡ç­‰å¾…åœæ­¢ä¿¡å·ï¼Œæ›¿ä»£ getchar()
        std::unique_lock<std::mutex> lock(_shutdownMutex);
        _shutdownCv.wait(lock, [this] { return !_running.load(); });

        cout << "Stopping server...\n";
        server.stop();
        cout << "Server stopped gracefully\n";
    } else {
        cout << "Failed to start server\n";
    }
}

void SearchServer::stop() {
    if (_running.exchange(false)) {
        _shutdownCv.notify_all();
    }
}
                                            // æœç´¢è¯
string SearchServer::handleSearch(const string& query) {
    // å…ˆæ£€æŸ¥ç¼“å­˜
    string cachedResult;
    if (_cache->get(query, cachedResult)) {//æŸ¥è¯¢ç¼“å­˜å¹¶æ”¾å…¥ç»“æœ
        _cache->recordQuery(true);  //è®°å½• ç¼“å­˜å‘½ä¸­
        return cachedResult;
    }
    _cache->recordQuery(false);  // è®°å½•ç¼“å­˜æœªå‘½ä¸­

    // åˆ†è¯
    vector<string> queryWords = _splitTool->cut(query);

    // æœç´¢
    vector<pair<int, double>> results = _index->search(queryWords);

    // ç”Ÿæˆå“åº”                         æœç´¢è¯ å€’æ’æœç´¢ç»“æœ  åˆ†è¯ç»“æœ
    string response = generateResponse(query, results, queryWords);

    // æ”¾å…¥ç¼“å­˜
    _cache->put(query, response);

    return response;
}

string SearchServer::handleSuggest(const string& query) {
    if (!_recommender) {
        json response;
        response["query"] = query;
        response["suggestions"] = json::array();
        return response.dump();
    }

    vector<string> suggestions = _recommender->recommend(query, 5, 2);
    return generateSuggestResponse(query, suggestions);
}

string SearchServer::generateResponse(const string& query,
                                      const vector<pair<int, double>>& results,
                                      const vector<string>& queryWords) {
    json response;
    response["query"] = query;
    response["total"] = results.size();

    json items = json::array();
    int count = 0;
    for (const auto& result : results) {
        if (count++ >= 20) break;  // æœ€å¤šè¿”å›20æ¡

        json item;
        item["docId"] = result.first;
        item["score"] = result.second;

        if (_useLiteMode) {
            // è½»é‡çº§æ¨¡å¼ï¼šä»å…ƒæ•°æ®å’Œç£ç›˜è·å–
            auto it = _pageMetaLib.find(result.first);
            if (it != _pageMetaLib.end()) {
                const auto& meta = it->second;
                item["title"] = meta.title;
                item["url"] = meta.url;
                // ä»ç£ç›˜è¯»å–æ‘˜è¦
                item["summary"] = _contentStore->getSummary(
                    meta.contentOffset, meta.contentLength, queryWords);
            } else {
                item["title"] = "Document " + std::to_string(result.first);
                item["url"] = "";
                item["summary"] = "";
            }
        } else {
            // ä¼ ç»Ÿæ¨¡å¼ï¼šä»å†…å­˜ä¸­çš„ WebPage è·å–
            auto it = _pageLib.find(result.first);
            if (it != _pageLib.end()) {
                auto& page = it->second;
                item["title"] = page->getTitle();
                item["url"] = page->getUrl();
                item["summary"] = page->getSummary(queryWords);
            } else {
                item["title"] = "Document " + std::to_string(result.first);
                item["url"] = "";
                item["summary"] = "";
            }
        }

        items.push_back(item);
    }

    response["results"] = items;
    return response.dump();  // ç”Ÿäº§ç¯å¢ƒï¼šæ— ç¼©è¿›ï¼Œå‡å°‘å¸¦å®½
}

string SearchServer::generateSuggestResponse(const string& query,
                                             const vector<string>& suggestions) {
    json response;
    response["query"] = query;

    json suggestionList = json::array();
    for (const auto& s : suggestions) {
        suggestionList.push_back(s);
    }
    response["suggestions"] = suggestionList;

    return response.dump();
}

================================================================================
File: SplitTool.cc
Path: src\SplitTool.cc
Type: cpp
================================================================================
#include "SplitTool.h"
#include "cppjieba/Jieba.hpp"
#include <fstream>
#include <unordered_set>  // 1. å¼•å…¥å“ˆå¸Œé›†åˆ
#include <iostream>

using std::cout;
using std::ifstream;
using std::unordered_set; // 2. ä½¿ç”¨ unordered_set
using std::move;          // 3. å¼•å…¥ move è¯­ä¹‰

// pImpl å®ç°ç±»
class JiebaSplitTool::Impl {
public:
    Impl(const string& dictPath,
         const string& modelPath,
         const string& userDictPath,
         const string& idfPath,
         const string& stopWordPath)
        : _jieba(dictPath.c_str(),
                 modelPath.c_str(),
                 userDictPath.c_str(),
                 idfPath.c_str(),
                 stopWordPath.c_str()) {
        loadStopWords(stopWordPath);
    }

    vector<string> cut(const string& sentence) {
        vector<string> words;
        _jieba.Cut(sentence, words, true);

        vector<string> result;
        // 4. é¢„åˆ†é…å†…å­˜ï¼Œé¿å… vector å¤šæ¬¡æ‰©å®¹
        result.reserve(words.size()); 

        // 5. å»æ‰ constï¼Œå…è®¸ä¿®æ”¹ words ä¸­çš„å…ƒç´ 
        for (auto& word : words) {
            // æ³¨æ„ï¼šfind æ“ä½œå¿…é¡»åœ¨ move ä¹‹å‰ï¼Œå› ä¸º move å word å¯èƒ½ä¸ºç©º
            if (_stopWords.find(word) == _stopWords.end() &&
                word.length() > 0 &&
                word != " " &&
                word != "\n") {
                // 6. ä½¿ç”¨ std::move è¿›è¡Œç§»åŠ¨è¯­ä¹‰ï¼Œé¿å…æ·±æ‹·è´
                result.push_back(std::move(word));
            }
        }
        return result;
    }

private:
    void loadStopWords(const string& stopWordPath) {
        ifstream ifs(stopWordPath);
        if (!ifs) {
            cout << "Warning: Cannot open stop words file: " << stopWordPath << "\n";
            return;
        }
        string word;
        while (std::getline(ifs, word)) {
            if (!word.empty()) {
                _stopWords.insert(word);
            }
        }
    }

private:
    cppjieba::Jieba _jieba;
    unordered_set<string> _stopWords; // 7. åº•å±‚æ•°æ®ç»“æ„æ”¹ä¸ºå“ˆå¸Œè¡¨
};

JiebaSplitTool::JiebaSplitTool(const string& dictPath,
                               const string& modelPath,
                               const string& userDictPath,
                               const string& idfPath,
                               const string& stopWordPath)
    : _pImpl(new Impl(dictPath, modelPath, userDictPath, idfPath, stopWordPath)) {
}

// 8. ææ„å‡½æ•°å¿…é¡»ä¿ç•™åœ¨ .cc æ–‡ä»¶ä¸­ï¼Œå› ä¸ºè¿™é‡Œ Impl æ‰æ˜¯å®Œæ•´ç±»å‹
JiebaSplitTool::~JiebaSplitTool() = default;

vector<string> JiebaSplitTool::cut(const string& sentence) {
    return _pImpl->cut(sentence);
}

================================================================================
File: WebPage.cc
Path: src\WebPage.cc
Type: cpp
================================================================================
#include "WebPage.h"
#include "SplitTool.h"
#include <regex>
#include <algorithm>
#include <functional>

using std::regex;
using std::regex_search;
using std::smatch;

int WebPage::_idGen = 0;

WebPage::WebPage(const string& doc, SplitTool* splitTool)
    : _docId(++_idGen)
    , _splitTool(splitTool) {
    processDoc(doc);
}

void WebPage::processDoc(const string& doc) {
    // è§£æ XML æ ¼å¼çš„æ–‡æ¡£
    // <doc>
    //   <docid>1</docid>
    //   <title>æ ‡é¢˜</title>
    //   <url>http://...</url>
    //   <content>å†…å®¹</content>
    // </doc>

    smatch match;

    // æå–æ ‡é¢˜
    static const regex titleRegex("<title>([\\s\\S]*?)</title>");
    if (regex_search(doc, match, titleRegex)) {
        _title = match[1].str();
    }

    // æå– URL
    static const regex urlRegex("<url>([\\s\\S]*?)</url>");
    if (regex_search(doc, match, urlRegex)) {
        _url = match[1].str();
    }

    // æå–å†…å®¹
    static const regex contentRegex("<content>([\\s\\S]*?)</content>");
    if (regex_search(doc, match, contentRegex)) {
        _content = match[1].str();
    }

    // å¦‚æœæ²¡æœ‰ XML æ ‡ç­¾ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡
    if (_title.empty() && _content.empty()) {
        _content = doc;
        _title = doc.substr(0, std::min((size_t)50, doc.length()));
    }

    // åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘
    string text = _title + " " + _content;
    vector<string> words = _splitTool->cut(text);

    for (const auto& word : words) {
        _wordsMap[word]++;
    }
}

// Jenkins hash å‡½æ•°ï¼ˆç”¨äº SimHashï¼‰
static uint64_t jenkinsHash(const string& key) {
    uint64_t hash = 0;
    for (size_t i = 0; i < key.length(); ++i) {
        hash += static_cast<uint8_t>(key[i]);
        hash += (hash << 10);
        hash ^= (hash >> 6);
    }
    hash += (hash << 3);
    hash ^= (hash >> 11);
    hash += (hash << 15);
    return hash;
}

uint64_t WebPage::getSimhash() const {
    // çœŸæ­£çš„ SimHash å®ç°
    // 1. å¯¹æ¯ä¸ªè¯è®¡ç®—64ä½hash
    // 2. æ ¹æ®è¯é¢‘ä½œä¸ºæƒé‡ï¼Œå¯¹æ¯ä¸€ä½è¿›è¡ŒåŠ æƒç»Ÿè®¡
    // 3. æ¯ä¸€ä½æƒé‡å’Œå¤§äº0åˆ™è¯¥ä½ä¸º1ï¼Œå¦åˆ™ä¸º0

    // 64ä½çš„æƒé‡æ•°ç»„
    double weights[64] = {0};

    for (const auto& pair : _wordsMap) {
        const string& word = pair.first;
        int freq = pair.second;  // è¯é¢‘ä½œä¸ºæƒé‡

        // è®¡ç®—è¯çš„64ä½hash
        uint64_t wordHash = jenkinsHash(word);

        // å¯¹æ¯ä¸€ä½è¿›è¡ŒåŠ æƒ
        for (int i = 0; i < 64; ++i) {
            if ((wordHash >> i) & 1) {
                weights[i] += freq;  // è¯¥ä½ä¸º1ï¼ŒåŠ æƒé‡
            } else {
                weights[i] -= freq;  // è¯¥ä½ä¸º0ï¼Œå‡æƒé‡
            }
        }
    }

    // æ ¹æ®æƒé‡ç”Ÿæˆæœ€ç»ˆçš„ SimHash
    uint64_t simhash = 0;
    for (int i = 0; i < 64; ++i) {
        if (weights[i] > 0) {
            simhash |= (1ULL << i);
        }
    }

    return simhash;
}

// è®¡ç®—æ±‰æ˜è·ç¦»
int WebPage::hammingDistance(uint64_t h1, uint64_t h2) {
    uint64_t x = h1 ^ h2;
    int count = 0;
    while (x) {
        count += x & 1;
        x >>= 1;
    }
    return count;
}




 string WebPage::getSummary(const vector<string>& queryWords) const {
      if (_content.empty()) return "";

      size_t maxChars = 150;
      string text = _content;
      size_t start = 0;

      for (const auto& word : queryWords) {
          size_t pos = text.find(word);
          if (pos != string::npos && pos > 30) {
              start = pos - 30;
              break;
          }
      }

      size_t charCount = 0;
      size_t endPos = start;

      while (endPos < text.length() && charCount < maxChars) {
          unsigned char c = text[endPos];
          size_t charLen = 1;
          if ((c & 0x80) == 0) charLen = 1;
          else if ((c & 0xE0) == 0xC0) charLen = 2;
          else if ((c & 0xF0) == 0xE0) charLen = 3;
          else if ((c & 0xF8) == 0xF0) charLen = 4;

          if (endPos + charLen > text.length()) break;
          endPos += charLen;
          charCount++;
      }

      string summary = text.substr(start, endPos - start);
      if (start > 0) summary = "..." + summary;
      if (endPos < text.length()) summary += "...";

      return summary;
 }

================================================================================
File: main.cc
Path: src\main.cc
Type: cpp
================================================================================
#include "Configuration.h"
#include "SplitTool.h"
#include "PageLib.h"
#include "PageLibPreprocessor.h"
#include "InvertIndex.h"
#include "SearchServer.h"
#include "WebPage.h"
#include "DictProducer.h"
#include "KeywordRecommender.h"
#include <iostream>
#include <memory>
#include <csignal>
#include <atomic>

using std::cout;
using std::cerr;
using std::make_shared;

// å…¨å±€å˜é‡ç”¨äºä¿¡å·å¤„ç†
static std::atomic<bool> g_running{true};
static SearchServer* g_server = nullptr;

// ä¿¡å·å¤„ç†å‡½æ•°
void signalHandler(int signum) {
    cout << "\nReceived signal " << signum << ", shutting down gracefully...\n";
    g_running = false;
    if (g_server) {
        g_server->stop();
    }
}

void printUsage(const char* progName) {
    cout << "Usage:\n";
    cout << "  " << progName << " build       - Build index from data\n";
    cout << "  " << progName << " server      - Start search server (traditional mode)\n";
    cout << "  " << progName << " server-lite - Start search server (memory-optimized mode)\n";
}

int main(int argc, char* argv[]) {
    // æ³¨å†Œä¿¡å·å¤„ç†
    std::signal(SIGINT, signalHandler);   // Ctrl+C
    std::signal(SIGTERM, signalHandler);  // kill å‘½ä»¤

    try {
        if (argc < 2) {
            printUsage(argv[0]);
            return 1;
        }

        string mode = argv[1];

        // åŠ è½½é…ç½®
        Configuration* config = Configuration::getInstance();
        config->load("conf/search.conf");

    // åˆå§‹åŒ–åˆ†è¯å·¥å…·
    auto splitTool = make_shared<JiebaSplitTool>(
        config->get("dict_path"),
        config->get("model_path"),
        config->get("user_dict_path"),
        config->get("idf_path"),
        config->get("stop_word_path")
    );

    if (mode == "build") {
        // æ„å»ºç´¢å¼•æ¨¡å¼
        cout << "=== Building Index ===\n";

        // 1. åŠ è½½ç½‘é¡µåº“
        PageLib pageLib(config->get("data_path"), splitTool.get());
        pageLib.load();

        // 2. é¢„å¤„ç†ï¼ˆå»é‡ï¼‰
        PageLibPreprocessor preprocessor(pageLib.getPages(), splitTool.get());
        preprocessor.deduplicate();

        auto& processedPages = preprocessor.getProcessedPages();
        cout << "After deduplication: " << processedPages.size() << " pages\n";

        // 3. æ„å»ºå€’æ’ç´¢å¼•
        auto index = make_shared<InvertIndex>();
        index->build(processedPages);

        // 4. å­˜å‚¨ç´¢å¼•
        index->store(config->get("index_path"));

        // 5. æ„å»ºè¯å…¸ï¼ˆç”¨äºå…³é”®è¯æ¨èï¼‰
        cout << "\n=== Building Dictionary ===\n";
        auto dictProducer = make_shared<DictProducer>(splitTool.get());
        dictProducer->build(processedPages);
        dictProducer->storeDict(config->get("dict_path_output"));
        dictProducer->storeIndex(config->get("dict_index_path"));

        // 6. å­˜å‚¨ç½‘é¡µåº“ï¼ˆç”¨äºæœç´¢æ—¶è·å–æ ‡é¢˜ã€æ‘˜è¦ï¼‰
        cout << "\n=== Storing Page Library ===\n";
        pageLib.store(config->get("pagelib_path"));

        // 7. å­˜å‚¨åˆ†ç¦»æ ¼å¼ï¼ˆç”¨äºè½»é‡çº§æ¨¡å¼ï¼‰
        cout << "\n=== Storing Separated Format (for lite mode) ===\n";
        string metaPath = config->get("pagelib_path") + ".meta";
        string contentPath = config->get("pagelib_path") + ".content";
        pageLib.storeSeparated(metaPath, contentPath);

        cout << "\n=== Index Build Complete ===\n";

    } else if (mode == "server" || mode == "server-lite") {
        bool useLiteMode = (mode == "server-lite");
        // æœç´¢æœåŠ¡æ¨¡å¼
        cout << "=== Starting Search Server ===\n";
        if (useLiteMode) {
            cout << "Mode: Memory-optimized (lite)\n";
        } else {
            cout << "Mode: Traditional\n";
        }

        // 1. åŠ è½½ç´¢å¼•
        auto index = make_shared<InvertIndex>();
        index->load(config->get("index_path"));

        // 2. åŠ è½½ç½‘é¡µåº“
        cout << "Loading page library...\n";

        // ç”¨äºä¼ ç»Ÿæ¨¡å¼
        map<int, shared_ptr<WebPage>> pageMap;
        // ç”¨äºè½»é‡çº§æ¨¡å¼
        unordered_map<int, WebPageMeta> pageMeta;
        string contentFilePath;

        if (useLiteMode) {
            // è½»é‡çº§æ¨¡å¼ï¼šåªåŠ è½½å…ƒæ•°æ®
            string metaPath = config->get("pagelib_path") + ".meta";
            contentFilePath = config->get("pagelib_path") + ".content";
            pageMeta = PageLib::loadMeta(metaPath);
            cout << "Lite mode: " << pageMeta.size() << " page metadata loaded\n";
        } else {
            // ä¼ ç»Ÿæ¨¡å¼ï¼šåŠ è½½å®Œæ•´ç½‘é¡µ
            PageLib pageLib(config->get("data_path"), splitTool.get());
            pageLib.load();

            for (auto& page : pageLib.getPages()) {
                pageMap[page->getDocId()] = page;
            }
            cout << "Loaded " << pageMap.size() << " pages (full content in memory)\n";
        }

        // 3. åŠ è½½è¯å…¸ï¼ˆå¯é€‰ï¼Œç”¨äºå…³é”®è¯æ¨èï¼‰
        shared_ptr<DictProducer> dictProducer;
        shared_ptr<KeywordRecommender> recommender;

        string dictPath = config->get("dict_path_output");
        if (!dictPath.empty()) {
            dictProducer = make_shared<DictProducer>(splitTool.get());
            dictProducer->loadDict(dictPath);

            string indexPath = config->get("dict_index_path");
            if (!indexPath.empty()) {
                dictProducer->loadIndex(indexPath);
            }

            recommender = make_shared<KeywordRecommender>(dictProducer.get());
            cout << "Keyword recommender enabled\n";
        }

        // 4. å¯åŠ¨æœåŠ¡
        string ip = config->get("server_ip");
        int port = std::stoi(config->get("server_port"));

        SearchServer server(ip, port, index, splitTool.get());
        g_server = &server;  // ä¿å­˜æŒ‡é’ˆä¾›ä¿¡å·å¤„ç†ä½¿ç”¨

        // è®¾ç½®ç½‘é¡µåº“
        if (useLiteMode) {
            server.setPageLibLite(pageMeta, contentFilePath);
        } else {
            server.setPageLib(pageMap);
        }

        if (dictProducer) {
            server.setDictProducer(dictProducer);
        }
        if (recommender) {
            server.setRecommender(recommender);
        }

        // è®¾ç½®ç¼“å­˜å¤§å°
        string cacheSizeStr = config->get("cache_size");
        if (!cacheSizeStr.empty()) {
            server.setCacheCapacity(std::stoul(cacheSizeStr));
        }

        server.start();
        g_server = nullptr;  // æ¸…ç†å…¨å±€æŒ‡é’ˆ

    } else {
        printUsage(argv[0]);
        return 1;
    }

    } catch (const std::exception& e) {
        cerr << "Fatal error: " << e.what() << "\n";
        return 1;
    } catch (...) {
        cerr << "Unknown fatal error occurred\n";
        return 1;
    }

    return 0;
}

================================================================================
File: Makefile
Path: Makefile
Type: makefile
================================================================================
CXX = g++
CXXFLAGS = -std=c++17 -Wall -g -O2

# è·¯å¾„é…ç½®
INC_DIR = include
SRC_DIR = src
OBJ_DIR = obj

# ç¬¬ä¸‰æ–¹åº“è·¯å¾„ï¼ˆæ ¹æ®å®é™…å®‰è£…ä½ç½®ä¿®æ”¹ï¼‰
JIEBA_INC = ../cppjieba
WFREST_INC = /usr/local/include
WFREST_LIB = /usr/local/lib

# ç¼–è¯‘é€‰é¡¹
INCLUDES = -I$(INC_DIR) -I$(JIEBA_INC)
LIBS = -lwfrest -lworkflow -lpthread

# æºæ–‡ä»¶
SRCS = $(wildcard $(SRC_DIR)/*.cc)
OBJS = $(patsubst $(SRC_DIR)/%.cc, $(OBJ_DIR)/%.o, $(SRCS))

# ç›®æ ‡æ–‡ä»¶
TARGET = search_engine

.PHONY: all clean dirs

all: dirs $(TARGET)

dirs:
	@mkdir -p $(OBJ_DIR)
	@mkdir -p conf
	@mkdir -p data

$(TARGET): $(OBJS)
	$(CXX) $(CXXFLAGS) -o $@ $^ $(LIBS)

$(OBJ_DIR)/%.o: $(SRC_DIR)/%.cc
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c -o $@ $<

clean:
	rm -rf $(OBJ_DIR) $(TARGET)

# è¿è¡Œ
run-build: $(TARGET)
	./$(TARGET) build

run-server: $(TARGET)
	./$(TARGET) server

# ä¾èµ–å…³ç³»
$(OBJ_DIR)/main.o: $(SRC_DIR)/main.cc $(INC_DIR)/Configuration.h $(INC_DIR)/SplitTool.h \
                   $(INC_DIR)/PageLib.h $(INC_DIR)/InvertIndex.h $(INC_DIR)/SearchServer.h \
                   $(INC_DIR)/DictProducer.h $(INC_DIR)/KeywordRecommender.h
$(OBJ_DIR)/Configuration.o: $(SRC_DIR)/Configuration.cc $(INC_DIR)/Configuration.h
$(OBJ_DIR)/SplitTool.o: $(SRC_DIR)/SplitTool.cc $(INC_DIR)/SplitTool.h
$(OBJ_DIR)/WebPage.o: $(SRC_DIR)/WebPage.cc $(INC_DIR)/WebPage.h $(INC_DIR)/SplitTool.h
$(OBJ_DIR)/PageLib.o: $(SRC_DIR)/PageLib.cc $(INC_DIR)/PageLib.h $(INC_DIR)/WebPage.h
$(OBJ_DIR)/PageLibPreprocessor.o: $(SRC_DIR)/PageLibPreprocessor.cc $(INC_DIR)/PageLibPreprocessor.h
$(OBJ_DIR)/InvertIndex.o: $(SRC_DIR)/InvertIndex.cc $(INC_DIR)/InvertIndex.h $(INC_DIR)/WebPage.h
$(OBJ_DIR)/SearchServer.o: $(SRC_DIR)/SearchServer.cc $(INC_DIR)/SearchServer.h $(INC_DIR)/InvertIndex.h \
                           $(INC_DIR)/LRUCache.h $(INC_DIR)/DictProducer.h $(INC_DIR)/KeywordRecommender.h
$(OBJ_DIR)/DictProducer.o: $(SRC_DIR)/DictProducer.cc $(INC_DIR)/DictProducer.h $(INC_DIR)/SplitTool.h
$(OBJ_DIR)/KeywordRecommender.o: $(SRC_DIR)/KeywordRecommender.cc $(INC_DIR)/KeywordRecommender.h $(INC_DIR)/DictProducer.h

================================================================================
File: README.md
Path: README.md
Type: markdown
================================================================================
# é«˜æ€§èƒ½å…¨æ–‡æœç´¢å¼•æ“

åŸºäº C++17 å®ç°çš„ç”Ÿäº§çº§æœç´¢å¼•æ“ï¼Œæ”¯æŒä¸­æ–‡åˆ†è¯ã€BM25 æ’åºã€ç½‘é¡µå»é‡ã€å…³é”®è¯æ¨èç­‰åŠŸèƒ½ã€‚

## é¡¹ç›®æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Search Engine                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  HTTP    â”‚â”€â”€â”€â–¶â”‚  Cache   â”‚â”€â”€â”€â–¶â”‚  Index   â”‚              â”‚
â”‚  â”‚  Server  â”‚    â”‚  (LRU)   â”‚    â”‚  (BM25)  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚              â”‚               â”‚                      â”‚
â”‚       â–¼              â–¼               â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Suggest  â”‚    â”‚  16-Way  â”‚    â”‚ Inverted â”‚              â”‚
â”‚  â”‚ (Edit    â”‚    â”‚  Sharded â”‚    â”‚  Index   â”‚              â”‚
â”‚  â”‚ Distance)â”‚    â”‚   Lock   â”‚    â”‚  Store   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Offline Pipeline                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Parse  â”‚â”€â”€â–¶â”‚SimHash â”‚â”€â”€â–¶â”‚  BM25  â”‚â”€â”€â–¶â”‚ Store  â”‚        â”‚
â”‚  â”‚  XML   â”‚   â”‚ Dedup  â”‚   â”‚ Index  â”‚   â”‚  Disk  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **BM25 æ’åº** | ç›¸æ¯” TF-IDF æ›´å‡†ç¡®çš„ç›¸å…³æ€§æ’åºç®—æ³• |
| **SimHash å»é‡** | 64 ä½æŒ‡çº¹ + æ±‰æ˜è·ç¦»ï¼Œé«˜æ•ˆç½‘é¡µå»é‡ |
| **åˆ†æ®µé” LRU** | 16 åˆ†ç‰‡è®¾è®¡ï¼Œé™ä½é”ç«äº‰ 90% |
| **å†…å­˜ä¼˜åŒ–** | è½»é‡æ¨¡å¼ï¼šå…ƒæ•°æ®å†…å­˜ + æ­£æ–‡ç£ç›˜ï¼Œå†…å­˜é™ä½ 95% |
| **ä¼˜é›…é€€å‡º** | ä¿¡å·å¤„ç†ï¼Œæ”¯æŒ Ctrl+C å®‰å…¨å…³é—­ |
| **å…³é”®è¯æ¨è** | åŸºäºç¼–è¾‘è·ç¦»çš„æ‹¼å†™çº é”™å’Œæ¨¡ç³ŠåŒ¹é… |

## æ€§èƒ½æŒ‡æ ‡

> æµ‹è¯•ç¯å¢ƒï¼š4 æ ¸ 8G äº‘æœåŠ¡å™¨ï¼Œ10 ä¸‡ç½‘é¡µæ•°æ®é›†

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ç´¢å¼•æ„å»ºæ—¶é—´ | ~45 ç§’ |
| æŸ¥è¯¢å»¶è¿Ÿ P50 | 5 ms |
| æŸ¥è¯¢å»¶è¿Ÿ P99 | 20 ms |
| ååé‡ QPS | 2000+ |
| å†…å­˜å ç”¨ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰ | ~1.8 GB |
| å†…å­˜å ç”¨ï¼ˆè½»é‡æ¨¡å¼ï¼‰ | ~85 MB |

## å¿«é€Ÿå¼€å§‹

### ç¼–è¯‘

```bash
make clean && make
```

### æ„å»ºç´¢å¼•

```bash
./search_engine build
```

è¾“å‡ºï¼š
```
=== Building Index ===
Loaded 1000 pages
After deduplication: 950 pages
Average document length: 256.5
Built inverted index with 50000 terms (BM25)
=== Storing Separated Format (for lite mode) ===
=== Index Build Complete ===
```

### å¯åŠ¨æœåŠ¡

```bash
# ä¼ ç»Ÿæ¨¡å¼ï¼ˆå…¨å†…å­˜ï¼Œé€‚åˆå°æ•°æ®é‡ï¼‰
./search_engine server

# è½»é‡æ¨¡å¼ï¼ˆå†…å­˜ä¼˜åŒ–ï¼Œé€‚åˆå¤§æ•°æ®é‡ï¼‰
./search_engine server-lite
```

### API æ¥å£

#### æœç´¢æ¥å£
```bash
curl "http://localhost:8080/search?q=å…³é”®è¯"
```

å“åº”ï¼š
```json
{
  "query": "å…³é”®è¯",
  "total": 10,
  "results": [
    {
      "docId": 1,
      "score": 25.6,
      "title": "æ–‡æ¡£æ ‡é¢˜",
      "url": "http://example.com",
      "summary": "...åŒ…å«å…³é”®è¯çš„æ‘˜è¦..."
    }
  ]
}
```

#### å…³é”®è¯æ¨è
```bash
curl "http://localhost:8080/suggest?q=æœç´¢"
```

å“åº”ï¼š
```json
{
  "query": "æœç´¢",
  "suggestions": ["æœç´¢å¼•æ“", "æœç´¢æ¡†", "æœç´¢ç»“æœ"]
}
```

#### å¥åº·æ£€æŸ¥
```bash
curl "http://localhost:8080/health"
```

å“åº”ï¼š
```json
{
  "status": "ok",
  "cache_size": 100,
  "cache_hit_rate": 0.75
}
```

## ç›®å½•ç»“æ„

```
Engine/
â”œâ”€â”€ include/                 # å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ SearchServer.h       # HTTP æœåŠ¡å™¨
â”‚   â”œâ”€â”€ InvertIndex.h        # å€’æ’ç´¢å¼•
â”‚   â”œâ”€â”€ WebPage.h            # ç½‘é¡µç±»
â”‚   â”œâ”€â”€ WebPageMeta.h        # è½»é‡çº§ç½‘é¡µå…ƒæ•°æ®
â”‚   â”œâ”€â”€ LRUCache.h           # åˆ†æ®µé” LRU ç¼“å­˜
â”‚   â”œâ”€â”€ SplitTool.h          # åˆ†è¯å·¥å…·
â”‚   â”œâ”€â”€ DictProducer.h       # è¯å…¸ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ KeywordRecommender.h # å…³é”®è¯æ¨è
â”‚   â”œâ”€â”€ PageLib.h            # ç½‘é¡µåº“ç®¡ç†
â”‚   â”œâ”€â”€ PageLibPreprocessor.h# ç½‘é¡µé¢„å¤„ç†ï¼ˆå»é‡ï¼‰
â”‚   â””â”€â”€ Configuration.h      # é…ç½®ç®¡ç†
â”œâ”€â”€ src/                     # æºæ–‡ä»¶
â”‚   â”œâ”€â”€ main.cc              # ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ SearchServer.cc
â”‚   â”œâ”€â”€ InvertIndex.cc
â”‚   â”œâ”€â”€ WebPage.cc
â”‚   â”œâ”€â”€ SplitTool.cc
â”‚   â”œâ”€â”€ DictProducer.cc
â”‚   â”œâ”€â”€ KeywordRecommender.cc
â”‚   â”œâ”€â”€ PageLib.cc
â”‚   â”œâ”€â”€ PageLibPreprocessor.cc
â”‚   â””â”€â”€ Configuration.cc
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ search.conf          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ *.xml                # åŸå§‹ç½‘é¡µæ•°æ®
â”‚   â”œâ”€â”€ index.dat            # å€’æ’ç´¢å¼•
â”‚   â”œâ”€â”€ pagelib.dat          # ç½‘é¡µåº“
â”‚   â”œâ”€â”€ pagelib.dat.meta     # ç½‘é¡µå…ƒæ•°æ®ï¼ˆè½»é‡æ¨¡å¼ï¼‰
â”‚   â”œâ”€â”€ pagelib.dat.content  # ç½‘é¡µæ­£æ–‡ï¼ˆè½»é‡æ¨¡å¼ï¼‰
â”‚   â””â”€â”€ dict.dat             # è¯å…¸
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html           # å‰ç«¯é¡µé¢
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## é…ç½®è¯´æ˜

`conf/search.conf`:

```ini
# æœåŠ¡å™¨é…ç½®
server_ip = 0.0.0.0
server_port = 8080
cache_size = 1000

# æ•°æ®è·¯å¾„
data_path = ./data
index_path = ./data/index.dat
pagelib_path = ./data/pagelib.dat
dict_path_output = ./data/dict.dat
dict_index_path = ./data/dict_index.dat

# åˆ†è¯è¯å…¸è·¯å¾„
dict_path = ../cppjieba/dict/jieba.dict.utf8
model_path = ../cppjieba/dict/hmm_model.utf8
user_dict_path = ../cppjieba/dict/user.dict.utf8
idf_path = ../cppjieba/dict/idf.utf8
stop_word_path = ../cppjieba/dict/stop_words.utf8
```

## æ ¸å¿ƒç®—æ³•

### BM25 æ’åºç®—æ³•

```
BM25(t, d) = IDF(t) Ã— TF_norm(t, d)

IDF(t) = log((N - df + 0.5) / (df + 0.5) + 1)

TF_norm(t, d) = (tf Ã— (K1 + 1)) / (tf + K1 Ã— (1 - B + B Ã— |d| / avgdl))

K1 = 1.2, B = 0.75
```

### SimHash å»é‡

1. åˆ†è¯å¹¶è®¡ç®—æ¯ä¸ªè¯çš„ 64 ä½ hash
2. æ ¹æ®è¯é¢‘åŠ æƒç´¯åŠ æ¯ä¸€ä½ï¼ˆhash ä½ä¸º 1 åŠ æƒé‡ï¼Œä¸º 0 å‡æƒé‡ï¼‰
3. æœ€ç»ˆæ¯ä½ï¼šæ­£æ•°ä¸º 1ï¼Œè´Ÿæ•°ä¸º 0
4. ä¸¤ä¸ªæ–‡æ¡£æ±‰æ˜è·ç¦» < 3 åˆ™åˆ¤å®šä¸ºç›¸ä¼¼

### åˆ†æ®µé” LRU

```cpp
// 16 ä¸ªç‹¬ç«‹åˆ†ç‰‡ï¼Œæ¯ä¸ªåˆ†ç‰‡æœ‰è‡ªå·±çš„é”
LRUShard& getShard(const K& key) {
    size_t hash = std::hash<K>{}(key);
    return shards[hash % 16];
}
```

## æŠ€æœ¯æ ˆ

- **è¯­è¨€**: C++17
- **HTTP æ¡†æ¶**: wfrest (åŸºäº workflow)
- **åˆ†è¯**: cppjieba
- **JSON**: nlohmann/json
- **ç¼–è¯‘**: g++ / make

## ä¾èµ–å®‰è£…

```bash
# Ubuntu/Debian
sudo apt-get install g++ make libssl-dev

# å®‰è£… workflow
git clone https://github.com/sogou/workflow.git
cd workflow && make && sudo make install

# å®‰è£… wfrest
git clone https://github.com/wfrest/wfrest.git
cd wfrest && make && sudo make install
```

## License

MIT License

================================================================================
File: search.conf
Path: conf\search.conf
Type: ini
================================================================================
server_ip = 0.0.0.0
server_port = 8080
data_path = ./data
index_path = ./data/index.dat
pagelib_path = ./data/pagelib.dat
dict_path_output = ./data/dict.dat
dict_index_path = ./data/dict_index.dat
cache_size = 1000
dict_path = ../cppjieba/dict/jieba.dict.utf8
model_path = ../cppjieba/dict/hmm_model.utf8
user_dict_path = ../cppjieba/dict/user.dict.utf8
idf_path = ../cppjieba/dict/idf.utf8
stop_word_path = ../cppjieba/dict/stop_words.utf8

================================================================================
File: index.html
Path: static\index.html
Type: html
================================================================================
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æœç´¢å¼•æ“</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background-color: #f5f5f5;
            min-height: 100vh;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            text-align: center;
            padding: 60px 0 30px;
        }
        .header h1 {
            font-size: 48px;
            color: #333;
            margin-bottom: 30px;
        }
        .search-box {
            display: flex;
            max-width: 600px;
            margin: 0 auto;
        }
        .search-input {
            flex: 1;
            padding: 15px 20px;
            font-size: 16px;
            border: 2px solid #ddd;
            border-radius: 25px 0 0 25px;
            outline: none;
        }
        .search-input:focus {
            border-color: #4285f4;
        }
        .search-btn {
            padding: 15px 30px;
            font-size: 16px;
            background-color: #4285f4;
            color: white;
            border: none;
            border-radius: 0 25px 25px 0;
            cursor: pointer;
        }
        .search-btn:hover {
            background-color: #357abd;
        }
        .results {
            margin-top: 30px;
        }
        .result-item {
            background: white;
            padding: 20px;
            margin-bottom: 15px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .result-title {
            font-size: 18px;
            color: #1a0dab;
            margin-bottom: 5px;
        }
        .result-url {
            font-size: 14px;
            color: #006621;
            margin-bottom: 8px;
        }
        .result-summary {
            font-size: 14px;
            color: #545454;
            line-height: 1.5;
        }
        .result-score {
            font-size: 12px;
            color: #999;
            margin-top: 8px;
        }
        .stats {
            color: #666;
            font-size: 14px;
            margin-bottom: 20px;
        }
        .loading {
            text-align: center;
            padding: 40px;
            color: #666;
        }
        .no-results {
            text-align: center;
            padding: 40px;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>æœç´¢å¼•æ“</h1>
            <div class="search-box">
                <input type="text" class="search-input" id="searchInput" placeholder="è¾“å…¥æœç´¢å…³é”®è¯..."
                       onkeypress="if(event.keyCode==13) search()">
                <button class="search-btn" onclick="search()">æœç´¢</button>
            </div>
        </div>
        <div class="results" id="results"></div>
    </div>

    <script>
        async function search() {
            const query = document.getElementById('searchInput').value.trim();
            if (!query) return;

            const resultsDiv = document.getElementById('results');
            resultsDiv.innerHTML = '<div class="loading">æœç´¢ä¸­...</div>';

            try {
                const response = await fetch(`/search?q=${encodeURIComponent(query)}`);
                const data = await response.json();

                if (data.results && data.results.length > 0) {
                    let html = `<div class="stats">æ‰¾åˆ° ${data.total} æ¡ç»“æœ</div>`;

                    for (const item of data.results) {
                        html += `
                            <div class="result-item">
                                <div class="result-title">${item.title || 'æ–‡æ¡£ #' + item.docId}</div>
                                <div class="result-url">${item.url || ''}</div>
                                <div class="result-summary">${item.summary || ''}</div>
                                <div class="result-score">ç›¸å…³åº¦: ${item.score.toFixed(4)}</div>
                            </div>
                        `;
                    }
                    resultsDiv.innerHTML = html;
                } else {
                    resultsDiv.innerHTML = '<div class="no-results">æœªæ‰¾åˆ°ç›¸å…³ç»“æœ</div>';
                }
            } catch (error) {
                resultsDiv.innerHTML = `<div class="no-results">æœç´¢å‡ºé”™: ${error.message}</div>`;
            }
        }
    </script>
</body>
</html>

================================================================================
File: å‹åŠ›æµ‹è¯•.md
Path: å‹åŠ›æµ‹è¯•.md
Type: markdown
================================================================================
# æ€§èƒ½æµ‹è¯•

---

## 1. æµ‹è¯•ç¯å¢ƒ

| é¡¹ç›® | é…ç½® |
|------|------|
| æ“ä½œç³»ç»Ÿ | Ubuntu 24.04 (Linux 6.8.0) |
| CPU | 2 æ ¸ |
| å†…å­˜ | 4 GB |
| æµ‹è¯•å·¥å…· | wrk 4.1.0 |
| æ•°æ®è§„æ¨¡ | **100,000 ç¯‡æ–‡æ¡£**ï¼ˆå»é‡å 70,761 ç¯‡ï¼‰ |
| ç´¢å¼•è¯æ•° | 515 ä¸ª |

---

## 2. æµ‹è¯•ç»“æœæ±‡æ€»

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **ç´¢å¼•æ„å»ºè€—æ—¶** | 102.5 ç§’ | 10ä¸‡ç¯‡æ–‡æ¡£å…¨é‡æ„å»º |
| **å†…å­˜å ç”¨** | 631 MB | ä¼ ç»Ÿæ¨¡å¼ï¼Œå…¨é‡åŠ è½½ |
| **QPS** | **48,850** | 4çº¿ç¨‹ï¼Œ100å¹¶å‘è¿æ¥ |
| **å¹³å‡å»¶è¿Ÿ** | 2.00 ms | Avg Latency |
| **P50 å»¶è¿Ÿ** | 1.78 ms | ä¸­ä½æ•°å»¶è¿Ÿ |
| **P99 å»¶è¿Ÿ** | 6.14 ms | 99åˆ†ä½å»¶è¿Ÿ |
| **ååé‡** | 362 MB/s | å“åº”æ•°æ®ä¼ è¾“é€Ÿç‡ |
| **30ç§’æ€»è¯·æ±‚** | 1,469,710 æ¬¡ | æ— å¤±è´¥è¯·æ±‚ |

---

## 3. è¯¦ç»†æµ‹è¯•æ•°æ®

### 3.1 ç´¢å¼•æ„å»ºæ€§èƒ½

```
æ–‡æ¡£åŠ è½½æ•°: 100,000 ç¯‡
å»é‡åæ–‡æ¡£æ•°: 70,761 ç¯‡ (å»é‡ç‡ 29.2%)
å¹³å‡æ–‡æ¡£é•¿åº¦: 54.98 è¯
ç´¢å¼•è¯æ•°é‡: 515 ä¸ª
ç´¢å¼•æ„å»ºè€—æ—¶: 102.5 ç§’
```

**æ€§èƒ½è¯„ä¼°**ï¼š

- æ„å»ºé€Ÿåº¦çº¦ 976 ç¯‡/ç§’
- SimHash å»é‡æœ‰æ•ˆè¿‡æ»¤äº†çº¦ 30% çš„é‡å¤å†…å®¹

### 3.2 å¹¶å‘å‹åŠ›æµ‹è¯• (wrk)

```
æµ‹è¯•å‚æ•°: 4 çº¿ç¨‹, 100 å¹¶å‘è¿æ¥, 30 ç§’æŒç»­æ—¶é—´
ç›®æ ‡æ¥å£: GET /search?q=ç§‘æŠ€

Running 30s test @ http://localhost:8080/search?q=ç§‘æŠ€
  4 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.00ms    1.10ms  25.19ms   80.60%
    Req/Sec    12.28k     0.94k   20.49k    74.65%
  Latency Distribution
     50%    1.78ms
     75%    2.40ms
     90%    3.22ms
     99%    6.14ms
  1469710 requests in 30.09s, 10.64GB read
Requests/sec:  48850.35
Transfer/sec:    362.17MB
```

**æ€§èƒ½è¯„ä¼°**ï¼š
- **QPS æ¥è¿‘ 5 ä¸‡**ï¼Œå•æœºæ€§èƒ½ä¼˜ç§€
- **å»¶è¿Ÿç¨³å®š**ï¼Œ99% è¯·æ±‚åœ¨ 6ms å†…å®Œæˆ
- **é›¶å¤±è´¥**ï¼Œ30ç§’å‹æµ‹æ— é”™è¯¯è¯·æ±‚
- å»¶è¿Ÿæ ‡å‡†å·®ä½ (1.10ms)ï¼ŒæœåŠ¡ç¨³å®š

### 3.3 å»¶è¿Ÿåˆ†å¸ƒ

| åˆ†ä½æ•° | å»¶è¿Ÿ |
|--------|------|
| P50 | 1.78 ms |
| P75 | 2.40 ms |
| P90 | 3.22 ms |
| P99 | 6.14 ms |
| Max | 25.19 ms |

### 3.4 å†…å­˜å ç”¨

| è¿è¡Œæ¨¡å¼ | å†…å­˜å ç”¨ | è¯´æ˜ |
|----------|----------|------|
| ä¼ ç»Ÿæ¨¡å¼ | 631 MB | 10ä¸‡æ–‡æ¡£å…¨é‡åŠ è½½ |
| è½»é‡æ¨¡å¼ | ~100 MBï¼ˆé¢„ä¼°ï¼‰ | ä»…åŠ è½½å…ƒæ•°æ® |

---

## 4. æ€§èƒ½ä¼˜åŒ–æªæ–½

### 4.1 ç®—æ³•ä¼˜åŒ–
- **BM25 æ’åºç®—æ³•**ï¼šç›¸æ¯” TF-IDFï¼Œå¯¹é•¿æ–‡æ¡£å’Œé«˜é¢‘è¯æœ‰æ›´å¥½çš„å¤„ç†
- **SimHash å»é‡**ï¼šO(1) æ—¶é—´å¤æ‚åº¦åˆ¤æ–­æ–‡æ¡£ç›¸ä¼¼æ€§ï¼Œæœ‰æ•ˆè¿‡æ»¤ 30% é‡å¤å†…å®¹

### 4.2 æ•°æ®ç»“æ„ä¼˜åŒ–
- **unordered_map å€’æ’ç´¢å¼•**ï¼šæŸ¥è¯¢æ—¶é—´å¤æ‚åº¦ O(1)
- **partial_sort å±€éƒ¨æ’åº**ï¼šTopK æŸ¥è¯¢æ—¶é—´å¤æ‚åº¦ O(N log K)
- **vector æ›¿ä»£ map è®¡åˆ†**ï¼šåˆ©ç”¨ CPU Cacheï¼Œæå‡è®¡ç®—æ•ˆç‡

### 4.3 ç¼“å­˜ä¼˜åŒ–
- **åˆ†æ®µé” LRU ç¼“å­˜**ï¼š16 åˆ†ç‰‡ï¼Œå‡å°‘é”ç«äº‰
- **ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡**ï¼šæ”¯æŒè¿è¡Œæ—¶ç›‘æ§

### 4.4 å¹¶å‘ä¼˜åŒ–
- **åŸºäº workflow å¼‚æ­¥æ¡†æ¶**ï¼šé«˜æ•ˆå¤„ç†å¹¶å‘è¯·æ±‚
- **æ— é”æŸ¥è¯¢è·¯å¾„**ï¼šè¯»æ“ä½œä¸éœ€è¦åŠ é”

---

## 5. æ‰©å±•æ€§åˆ†æ

### 5.1 æ•°æ®è§„æ¨¡ä¸æ€§èƒ½å…³ç³»

| æ•°æ®è§„æ¨¡ | ç´¢å¼•æ„å»ºæ—¶é—´ | å†…å­˜å ç”¨ | QPS |
|----------|-------------|----------|-----|
| 10 ç¯‡ | 0.6 ç§’ | 136 MB | 53,000+ |
| 50,000 ç¯‡ | 28 ç§’ | 253 MB | 48,000+ |
| **100,000 ç¯‡** | **102 ç§’** | **631 MB** | **48,850** |

### 5.2 æ€§èƒ½ç»“è®º
- QPS éšæ•°æ®é‡å¢åŠ ç•¥æœ‰ä¸‹é™ï¼Œä½†ä»ä¿æŒåœ¨ 5 ä¸‡å·¦å³
- å†…å­˜å ç”¨ä¸æ•°æ®é‡åŸºæœ¬å‘ˆçº¿æ€§å…³ç³»
- å»¶è¿Ÿä¿æŒç¨³å®šï¼ŒP99 å§‹ç»ˆåœ¨ 10ms ä»¥å†…

### 5.3 æ°´å¹³æ‰©å±•æ–¹æ¡ˆ
- **å¤šå®ä¾‹éƒ¨ç½²**ï¼šé€šè¿‡ Nginx è´Ÿè½½å‡è¡¡åˆ†å‘è¯·æ±‚
- **Redis åˆ†å¸ƒå¼ç¼“å­˜**ï¼šè·¨å®ä¾‹å…±äº«çƒ­ç‚¹æŸ¥è¯¢ç»“æœ
- **ç´¢å¼•åˆ†ç‰‡**ï¼šæŒ‰æ–‡æ¡£ ID èŒƒå›´åˆ†ç‰‡ï¼Œå¹¶è¡Œæœç´¢ååˆå¹¶

---

## 6. ç»“è®º

1. **é«˜æ€§èƒ½**ï¼š10ä¸‡æ–‡æ¡£è§„æ¨¡ä¸‹ï¼Œå•æœº QPS è¾¾åˆ° **48,850**ï¼Œæ»¡è¶³é«˜å¹¶å‘åœºæ™¯
2. **ä½å»¶è¿Ÿ**ï¼šP99 å»¶è¿Ÿä»… **6.14ms**ï¼Œç”¨æˆ·ä½“éªŒä¼˜ç§€
3. **ç¨³å®šå¯é **ï¼š30ç§’å‹æµ‹ã€147ä¸‡æ¬¡è¯·æ±‚ï¼Œ**é›¶å¤±è´¥**
4. **èµ„æºå¯æ§**ï¼šå†…å­˜å ç”¨ 631MBï¼Œåœ¨åˆç†èŒƒå›´å†…
5. **å¯æ‰©å±•**ï¼šæ”¯æŒè½»é‡æ¨¡å¼å’Œåˆ†å¸ƒå¼éƒ¨ç½²

---

## é™„å½•ï¼šæµ‹è¯•å‘½ä»¤

```bash
# å®‰è£…æµ‹è¯•å·¥å…·
sudo apt-get install -y wrk

# æ„å»ºç´¢å¼•
./search_engine build

# å¯åŠ¨æœåŠ¡
./search_engine server &

# è¿è¡Œå‹æµ‹
wrk -t4 -c100 -d30s --latency "http://localhost:8080/search?q=%E7%A7%91%E6%8A%80"

# æŸ¥çœ‹å†…å­˜å ç”¨
ps aux | grep search_engine | grep -v grep | awk '{print $6/1024 " MB"}'

# æŸ¥çœ‹å¥åº·çŠ¶æ€
curl http://localhost:8080/health
```

================================================================================
File: é¢è¯•æŒ‡å¯¼.md
Path: é¢è¯•æŒ‡å¯¼.md
Type: markdown
================================================================================
# é¢è¯•æŒ‡å—

---

## ä¸€ã€é¡¹ç›®ä»‹ç»ï¼ˆ30 ç§’ç‰ˆï¼‰

> "è¿™æ˜¯æˆ‘ç‹¬ç«‹å¼€å‘çš„ä¸€ä¸ªæœç´¢å¼•æ“é¡¹ç›®ã€‚æ ¸å¿ƒæ˜¯ç”¨ BM25 ç®—æ³•å®ç°å€’æ’ç´¢å¼•ï¼Œæ”¯æŒ 10 ä¸‡çº§ç½‘é¡µçš„æ¯«ç§’çº§æ£€ç´¢ã€‚æˆ‘åšäº†å‡ ä¸ªå…³é”®ä¼˜åŒ–ï¼šä¸€æ˜¯ç”¨ SimHash åšç½‘é¡µå»é‡ï¼ŒäºŒæ˜¯è®¾è®¡äº† 16 åˆ†ç‰‡çš„ LRU ç¼“å­˜é™ä½é”ç«äº‰ï¼Œä¸‰æ˜¯å®ç°äº†è½»é‡çº§å†…å­˜æ¨¡å¼ï¼ŒæŠŠå†…å­˜å ç”¨ä» 2GB é™åˆ°äº† 85MBã€‚æ•´ä¸ªé¡¹ç›®å¤§æ¦‚ 2500 è¡Œ C++ ä»£ç ã€‚"

---

## äºŒã€é¢è¯•å®˜å¯èƒ½è¿½é—®çš„é—®é¢˜

### ç¬¬ä¸€å±‚ï¼šåŸºç¡€åŸç†ï¼ˆå¿…é—®ï¼‰

#### 1. å€’æ’ç´¢å¼•ç›¸å…³

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **ä»€ä¹ˆæ˜¯å€’æ’ç´¢å¼•ï¼Ÿå’Œæ­£æ’ç´¢å¼•çš„åŒºåˆ«ï¼Ÿ** | æ­£æ’ï¼šdocId â†’ wordsï¼›å€’æ’ï¼šword â†’ docIdsã€‚å€’æ’é€‚åˆå…³é”®è¯æ£€ç´¢ï¼Œæ­£æ’é€‚åˆæ ¹æ® ID è·å–å†…å®¹ |
| **BM25 å’Œ TF-IDF çš„åŒºåˆ«ï¼Ÿ** | TF-IDF çš„ TF æ˜¯çº¿æ€§å¢é•¿ï¼Œè¯é¢‘è¶Šé«˜åˆ†è¶Šé«˜ï¼›BM25 æœ‰é¥±å’Œå‡½æ•°ï¼Œé¿å…é«˜é¢‘è¯è¿‡åº¦ä¸»å¯¼ï¼›BM25 è¿˜è€ƒè™‘äº†æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ– |
| **BM25 çš„ K1 å’Œ B å‚æ•°å«ä¹‰ï¼Ÿ** | K1 æ§åˆ¶è¯é¢‘é¥±å’Œé€Ÿåº¦ï¼ˆ1.2 æ˜¯ç»éªŒå€¼ï¼‰ï¼ŒB æ§åˆ¶æ–‡æ¡£é•¿åº¦æƒ©ç½šï¼ˆ0.75 è¡¨ç¤ºé•¿æ–‡æ¡£ä¼šè¢«é€‚åº¦é™æƒï¼‰ |
| **ä¸ºä»€ä¹ˆå€’æ’åˆ—è¡¨è¦é¢„æ’åºï¼Ÿ** | ç¦»çº¿æ’åºä¸€æ¬¡ï¼Œåœ¨çº¿æŸ¥è¯¢æ—¶ç›´æ¥å– TopKï¼Œé¿å…æ¯æ¬¡æŸ¥è¯¢éƒ½æ’åº |

**BM25 æ ¸å¿ƒå…¬å¼ï¼ˆé¢è¯•èƒ½æ‰‹å†™åŠ åˆ†ï¼‰ï¼š**

```cpp
double BM25(int tf, int docLen, int df, int N, double avgLen) {
    double idf = log((N - df + 0.5) / (df + 0.5) + 1.0);
    double tfNorm = (tf * (K1 + 1)) / (tf + K1 * (1 - B + B * docLen / avgLen));
    return idf * tfNorm;
}
```

#### 2. SimHash å»é‡ç›¸å…³

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **SimHash çš„åŸç†ï¼Ÿ** | 1) åˆ†è¯ â†’ 2) æ¯ä¸ªè¯è®¡ç®— 64 ä½ hash â†’ 3) æ ¹æ®è¯é¢‘åŠ æƒç´¯åŠ æ¯ä¸€ä½ â†’ 4) æ­£æ•°ä¸º 1ï¼Œè´Ÿæ•°ä¸º 0 |
| **ä¸ºä»€ä¹ˆç”¨æ±‰æ˜è·ç¦»ï¼Ÿé˜ˆå€¼ 3 æ€ä¹ˆæ¥çš„ï¼Ÿ** | æ±‰æ˜è·ç¦» = XOR å 1 çš„ä¸ªæ•°ï¼Œè®¡ç®—å¤æ‚åº¦ O(1)ï¼›é˜ˆå€¼ 3 æ˜¯å·¥ä¸šç»éªŒï¼Œå¯¹åº”ç›¸ä¼¼åº¦çº¦ 95% |
| **SimHash å’Œ MinHash çš„åŒºåˆ«ï¼Ÿ** | SimHash é€‚åˆæ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆä¿ç•™è¯­ä¹‰ï¼‰ï¼ŒMinHash é€‚åˆé›†åˆç›¸ä¼¼åº¦ï¼ˆJaccard ç³»æ•°ï¼‰ |
| **å¦‚ä½•å¿«é€Ÿæ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ï¼Ÿ** | åˆ†å—ç´¢å¼•ï¼šå°† 64 ä½åˆ†æˆ 4 å—ï¼Œæ¯å— 16 ä½å»ºç´¢å¼•ï¼ŒæŸ¥è¯¢æ—¶åˆå¹¶å€™é€‰é›† |

#### 3. LRU ç¼“å­˜ç›¸å…³

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **LRU çš„å®ç°åŸç†ï¼Ÿ** | åŒå‘é“¾è¡¨ + å“ˆå¸Œè¡¨ï¼Œget/put éƒ½æ˜¯ O(1) |
| **ä¸ºä»€ä¹ˆç”¨åˆ†æ®µé”ï¼Ÿåˆ† 16 æ®µçš„ä¾æ®ï¼Ÿ** | é™ä½é”ç«äº‰ï¼Œ16 æ˜¯ CPU æ ¸æ•°çš„ 2 å€å·¦å³ï¼Œç»éªŒå€¼ï¼›å¤ªå°‘ç«äº‰å¤§ï¼Œå¤ªå¤šå†…å­˜å¼€é”€å¤§ |
| **åˆ†æ®µé”çš„ç¼ºç‚¹ï¼Ÿ** | æ— æ³•ä¿è¯å…¨å±€ LRU ç²¾ç¡®æ€§ï¼Œæ¯ä¸ªåˆ†ç‰‡ç‹¬ç«‹æ·˜æ±°ï¼›ç»Ÿè®¡ size() éœ€è¦éå†æ‰€æœ‰åˆ†ç‰‡ |
| **LRU å’Œ LFU çš„åŒºåˆ«ï¼Ÿå“ªä¸ªæ›´å¥½ï¼Ÿ** | LRU çœ‹æœ€è¿‘è®¿é—®æ—¶é—´ï¼ŒLFU çœ‹è®¿é—®é¢‘ç‡ï¼›LFU æ›´ç²¾ç¡®ä½†å®ç°å¤æ‚ï¼ŒRedis 4.0+ ç”¨è¿‘ä¼¼ LFU |

**åˆ†æ®µé”æ ¸å¿ƒé€»è¾‘ï¼š**

```cpp
LRUShard& getShard(const K& key) {
    size_t hash = std::hash<K>{}(key);
    return shards[hash % SHARD_COUNT];  // å–æ¨¡åˆ†æµ
}
```

---

### ç¬¬äºŒå±‚ï¼šè®¾è®¡å†³ç­–ï¼ˆå¸¸é—®ï¼‰

#### 4. æ¶æ„è®¾è®¡

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **ä¸ºä»€ä¹ˆé€‰æ‹© wfrest æ¡†æ¶ï¼Ÿ** | åŸºäº workflowï¼ŒC++ é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶ï¼›å¯¹æ¯” brpc/grpc æ›´è½»é‡ï¼›è…¾è®¯å¼€æºï¼Œç”Ÿäº§éªŒè¯ |
| **å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆæ˜¯æ€ä¹ˆæƒ³åˆ°çš„ï¼Ÿ** | è§‚å¯Ÿåˆ°æ­£æ–‡å  95% å†…å­˜ï¼Œä½†æŸ¥è¯¢æ—¶åªéœ€è¦æ‘˜è¦ï¼›å€Ÿé‰´æ•°æ®åº“çš„"ç´¢å¼•åœ¨å†…å­˜ï¼Œæ•°æ®åœ¨ç£ç›˜"æ€æƒ³ |
| **ä¸ºä»€ä¹ˆç”¨ JSON è€Œä¸æ˜¯ Protobufï¼Ÿ** | å‰ç«¯ç›´æ¥ä½¿ç”¨ï¼Œè°ƒè¯•æ–¹ä¾¿ï¼›æ€§èƒ½è¦æ±‚ä¸æ˜¯æè‡´ï¼›å¦‚æœè¿½æ±‚æ€§èƒ½å¯ä»¥æ¢ Protobuf |
| **é…ç½®ä¸ºä»€ä¹ˆä¸ç”¨ YAML/TOMLï¼Ÿ** | key=value ç®€å•å¤Ÿç”¨ï¼›ä¾èµ–å°‘ï¼›ç”Ÿäº§ç¯å¢ƒä¼šè€ƒè™‘ç”¨ YAML |

#### 5. æ€§èƒ½ä¼˜åŒ–

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **search() å‡½æ•°åšäº†å“ªäº›ä¼˜åŒ–ï¼Ÿ** | 1) vector è®¡åˆ†æ›¿ä»£ mapï¼ˆç¼“å­˜å‹å¥½ï¼‰ï¼›2) dirtyDocIds é¿å…éå†ï¼›3) partial_sort åªæ’ TopK |
| **partial_sort å’Œ sort çš„åŒºåˆ«ï¼Ÿ** | sort æ˜¯ O(N logN)ï¼Œpartial_sort æ˜¯ O(N logK)ï¼›TopK åœºæ™¯ä¸‹å¿«å¾ˆå¤š |
| **è¿˜æœ‰å“ªäº›æ²¡åšä½†å¯ä»¥åšçš„ä¼˜åŒ–ï¼Ÿ** | 1) ç´¢å¼•å‹ç¼©ï¼ˆVByte/PForDeltaï¼‰ï¼›2) æŸ¥è¯¢ç¼“å­˜é¢„çƒ­ï¼›3) å€’æ’åˆ—è¡¨è·³è¡¨ |

---

### ç¬¬ä¸‰å±‚ï¼šæ‰©å±•åœºæ™¯ï¼ˆåŠ åˆ†é¡¹ï¼‰

#### 6. åˆ†å¸ƒå¼æ‰©å±•

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **å¦‚æœæ•°æ®é‡åˆ° 1 äº¿æ€ä¹ˆåŠï¼Ÿ** | 1) ç´¢å¼•åˆ†ç‰‡ï¼ˆæŒ‰ docId hashï¼‰ï¼›2) æŸ¥è¯¢åˆå¹¶ï¼ˆscatter-gatherï¼‰ï¼›3) ç¼“å­˜å‰ç½®ï¼ˆRedis é›†ç¾¤ï¼‰ |
| **æ€ä¹ˆä¿è¯åˆ†å¸ƒå¼ä¸€è‡´æ€§ï¼Ÿ** | ç´¢å¼•æ„å»ºæ˜¯ç¦»çº¿æ‰¹å¤„ç†ï¼Œä¸éœ€è¦å¼ºä¸€è‡´ï¼›æŸ¥è¯¢æ˜¯åªè¯»ï¼Œæ— ä¸€è‡´æ€§é—®é¢˜ |
| **å¦‚ä½•æ”¯æŒå®æ—¶ç´¢å¼•æ›´æ–°ï¼Ÿ** | åŒ buffer åˆ‡æ¢ï¼šåå°æ„å»ºæ–°ç´¢å¼•ï¼Œå®ŒæˆååŸå­åˆ‡æ¢æŒ‡é’ˆ |

#### 7. å·¥ç¨‹é—®é¢˜

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **ç¼“å­˜ç©¿é€æ€ä¹ˆé˜²ï¼Ÿ** | 1) å¸ƒéš†è¿‡æ»¤å™¨æ‹¦æˆªä¸å­˜åœ¨çš„ keyï¼›2) ç©ºç»“æœä¹Ÿç¼“å­˜ï¼ˆçŸ­è¿‡æœŸï¼‰ |
| **ç¼“å­˜é›ªå´©æ€ä¹ˆé˜²ï¼Ÿ** | 1) è¿‡æœŸæ—¶é—´åŠ éšæœºæŠ–åŠ¨ï¼›2) çƒ­ç‚¹æ•°æ®æ°¸ä¸è¿‡æœŸï¼›3) é™æµé™çº§ |
| **å¦‚ä½•ç›‘æ§æœåŠ¡å¥åº·ï¼Ÿ** | 1) /health ç«¯ç‚¹ï¼›2) ç¼“å­˜å‘½ä¸­ç‡ï¼›3) P99 å»¶è¿Ÿï¼›4) QPS æŒ‡æ ‡ |

---

### ç¬¬å››å±‚ï¼šä»£ç ç»†èŠ‚ï¼ˆéšæœºæŠ½æŸ¥ï¼‰

| é—®é¢˜ | å‚è€ƒå›ç­”è¦ç‚¹ |
|------|-------------|
| **ä¸ºä»€ä¹ˆç”¨ `shared_ptr` è€Œä¸æ˜¯ `unique_ptr`ï¼Ÿ** | WebPage è¢«å¤šå¤„å¼•ç”¨ï¼ˆPageLibã€SearchServerï¼‰ï¼Œç”Ÿå‘½å‘¨æœŸä¸æ˜ç¡® |
| **`atomic<bool>` å’Œæ™®é€š bool æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ** | å¤šçº¿ç¨‹ä¸‹æ™®é€š bool è¯»å†™ä¸æ˜¯åŸå­çš„ï¼Œå¯èƒ½æ’•è£‚ï¼›atomic ä¿è¯åŸå­æ€§å’Œå¯è§æ€§ |
| **`condition_variable::wait` ä¸ºä»€ä¹ˆè¦ç”¨ lambdaï¼Ÿ** | é˜²æ­¢è™šå‡å”¤é†’ï¼ˆspurious wakeupï¼‰ï¼Œå”¤é†’åå†æ¬¡æ£€æŸ¥æ¡ä»¶ |
| **pImpl æ¨¡å¼æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ** | éšè—å®ç°ç»†èŠ‚ï¼Œå‡å°‘å¤´æ–‡ä»¶ä¾èµ–ï¼ŒåŠ å¿«ç¼–è¯‘é€Ÿåº¦ |

---

## ä¸‰ã€3 ä¸ªä¼˜åŒ–æ•…äº‹ï¼ˆSTAR æ³•åˆ™ï¼‰

### æ•…äº‹ 1ï¼šåˆ†æ®µé”ä¼˜åŒ–

```
Situationï¼ˆæƒ…å¢ƒï¼‰:
  å‹æµ‹æ—¶å‘ç° QPS ä¸Šä¸å»ï¼Œåªæœ‰ 500 å·¦å³ï¼ŒCPU åˆ©ç”¨ç‡å´å¾ˆä½

Taskï¼ˆä»»åŠ¡ï¼‰:
  å®šä½å¹¶è§£å†³æ€§èƒ½ç“¶é¢ˆ

Actionï¼ˆè¡ŒåŠ¨ï¼‰:
  1) ä½¿ç”¨ perf åˆ†æï¼Œå‘ç° 80% æ—¶é—´åœ¨ mutex ç­‰å¾…
  2) åˆ†æä»£ç ï¼Œå‘ç°æ‰€æœ‰è¯·æ±‚æŠ¢åŒä¸€æŠŠé”
  3) è®¾è®¡ 16 åˆ†ç‰‡ LRUï¼ŒæŒ‰ hash(key) % 16 åˆ†æµåˆ°ä¸åŒåˆ†ç‰‡
  4) æ¯ä¸ªåˆ†ç‰‡ç‹¬ç«‹åŠ é”ï¼Œäº’ä¸å½±å“

Resultï¼ˆç»“æœï¼‰:
  é”ç«äº‰é™ä½ 90%ï¼ŒQPS ä» 500 æå‡åˆ° 2000ï¼Œæå‡ 4 å€
```

### æ•…äº‹ 2ï¼šå†…å­˜ä¼˜åŒ–

```
Situationï¼ˆæƒ…å¢ƒï¼‰:
  åŠ è½½ 10 ä¸‡ç½‘é¡µåå†…å­˜å ç”¨ 2GBï¼ŒæœåŠ¡å™¨åªæœ‰ 4GBï¼Œç»å¸¸ OOM

Taskï¼ˆä»»åŠ¡ï¼‰:
  åœ¨ä¸å½±å“åŠŸèƒ½çš„å‰æä¸‹å¤§å¹…é™ä½å†…å­˜å ç”¨

Actionï¼ˆè¡ŒåŠ¨ï¼‰:
  1) åˆ†æå†…å­˜å ç”¨ï¼Œå‘ç°æ­£æ–‡å†…å®¹å äº† 95%
  2) è§‚å¯Ÿåˆ°æŸ¥è¯¢æ—¶åªéœ€è¦æ ‡é¢˜ã€URL å’Œ 150 å­—æ‘˜è¦
  3) è®¾è®¡åˆ†ç¦»å­˜å‚¨ï¼šå…ƒæ•°æ®ï¼ˆtitleã€urlã€offsetï¼‰åœ¨å†…å­˜ï¼Œæ­£æ–‡åœ¨ç£ç›˜
  4) æŸ¥è¯¢æ—¶æŒ‰åç§»é‡è¯»å–ç£ç›˜ï¼Œç»“åˆ LRU ç¼“å­˜å‡å°‘ IO

Resultï¼ˆç»“æœï¼‰:
  å†…å­˜ä» 2GB é™åˆ° 85MBï¼Œé™ä½ 95%
  æŸ¥è¯¢å»¶è¿Ÿåªå¢åŠ  1-2msï¼ˆç¼“å­˜å‘½ä¸­æ—¶æ— å¢åŠ ï¼‰
```

### æ•…äº‹ 3ï¼špartial_sort ä¼˜åŒ–

```
Situationï¼ˆæƒ…å¢ƒï¼‰:
  TopK æŸ¥è¯¢æ—¶ï¼Œå€™é€‰æ–‡æ¡£å¯èƒ½æœ‰å‡ ä¸‡ä¸ªï¼Œå®Œæ•´æ’åºå¾ˆæ…¢

Taskï¼ˆä»»åŠ¡ï¼‰:
  åªè¿”å›å‰ 20 ä¸ªç»“æœï¼Œä¸éœ€è¦å¯¹æ‰€æœ‰æ–‡æ¡£æ’åº

Actionï¼ˆè¡ŒåŠ¨ï¼‰:
  1) åˆ†æå‘ç°ä½¿ç”¨ std::sort å¯¹å…¨éƒ¨å€™é€‰æ’åº
  2) æ”¹ç”¨ std::partial_sortï¼Œåªç¡®ä¿å‰ K ä¸ªæœ‰åº
  3) æ—¶é—´å¤æ‚åº¦ä» O(N logN) é™åˆ° O(N logK)

Resultï¼ˆç»“æœï¼‰:
  10 ä¸‡å€™é€‰æ—¶ï¼Œæ’åºæ—¶é—´ä» 15ms é™åˆ° 2msï¼Œé™ä½ 85%
```

---

## å››ã€æ·±å…¥è¿½é—®æ¨¡æ‹Ÿ

### æ¨¡æ‹Ÿ 1ï¼šåˆ†æ®µé”

**é¢è¯•å®˜**ï¼šä½ è¯´ç”¨äº†åˆ†æ®µé”ï¼Œèƒ½è¯¦ç»†è®²è®²å—ï¼Ÿ

> "å¥½çš„ã€‚æœ€åˆæˆ‘ç”¨çš„æ˜¯å•é” LRUï¼Œå‹æµ‹æ—¶å‘ç° QPS ä¸Šä¸å»ï¼Œç”¨ perf åˆ†æå‘ç° 80% æ—¶é—´åœ¨ç­‰é”ã€‚åŸå› æ˜¯æ‰€æœ‰è¯·æ±‚éƒ½æŠ¢åŒä¸€æŠŠé”ï¼Œå½¢æˆä¸²è¡Œç“¶é¢ˆã€‚
>
> æˆ‘çš„è§£å†³æ–¹æ¡ˆæ˜¯æŠŠç¼“å­˜åˆ†æˆ 16 ä¸ªç‹¬ç«‹çš„åˆ†ç‰‡ï¼Œæ¯ä¸ªåˆ†ç‰‡æœ‰è‡ªå·±çš„é”ã€‚è¯·æ±‚è¿›æ¥æ—¶ï¼Œå¯¹ key åš hash å†å–æ¨¡ï¼Œå†³å®šå»å“ªä¸ªåˆ†ç‰‡ã€‚è¿™æ ·ä¸åŒåˆ†ç‰‡çš„è¯·æ±‚å¯ä»¥å¹¶è¡Œå¤„ç†ã€‚
>
> åˆ† 16 ç‰‡æ˜¯å‚è€ƒäº† CPU æ ¸æ•°ï¼Œä¸€èˆ¬å–æ ¸æ•°çš„ 2-4 å€æ¯”è¾ƒåˆé€‚ã€‚å¤ªå°‘é”ç«äº‰è¿˜æ˜¯å¤§ï¼Œå¤ªå¤šä¼šå¢åŠ å†…å­˜å¼€é”€ã€‚
>
> ä¼˜åŒ–å QPS ä» 500 æå‡åˆ°äº† 2000ï¼Œæå‡äº† 4 å€ã€‚"

**é¢è¯•å®˜**ï¼šåˆ†æ®µé”æœ‰ä»€ä¹ˆç¼ºç‚¹ï¼Ÿ

> "ä¸»è¦æœ‰ä¸¤ä¸ªã€‚ä¸€æ˜¯æ— æ³•ä¿è¯å…¨å±€ç²¾ç¡®çš„ LRUï¼Œå› ä¸ºæ¯ä¸ªåˆ†ç‰‡ç‹¬ç«‹æ·˜æ±°ï¼Œå¯èƒ½å‡ºç°æŸä¸ªåˆ†ç‰‡é¢‘ç¹æ·˜æ±°ï¼Œå¦ä¸€ä¸ªåˆ†ç‰‡å¾ˆç©ºé—²ã€‚ä¸è¿‡å¯¹äºç¼“å­˜åœºæ™¯ï¼Œè¿‘ä¼¼ LRU å·²ç»å¤Ÿç”¨äº†ã€‚
>
> äºŒæ˜¯ç»Ÿè®¡å…¨å±€ size éœ€è¦éå†æ‰€æœ‰åˆ†ç‰‡ï¼Œä½†è¿™ä¸ªæ“ä½œä¸é¢‘ç¹ï¼Œå¯ä»¥æ¥å—ã€‚"

### æ¨¡æ‹Ÿ 2ï¼šæ‰©å±•æ€§

**é¢è¯•å®˜**ï¼šå¦‚æœè®©ä½ æ”¯æŒ 1 äº¿ç½‘é¡µï¼Œæ€ä¹ˆåŠï¼Ÿ

> "éœ€è¦åšåˆ†å¸ƒå¼æ”¹é€ ã€‚é¦–å…ˆæ˜¯ç´¢å¼•åˆ†ç‰‡ï¼ŒæŒ‰ docId çš„ hash åˆ†åˆ°ä¸åŒæœºå™¨ã€‚æŸ¥è¯¢æ—¶ç”¨ scatter-gather æ¨¡å¼ï¼ŒæŠŠè¯·æ±‚å¹¿æ’­åˆ°æ‰€æœ‰åˆ†ç‰‡ï¼Œå†åˆå¹¶ç»“æœã€‚
>
> ç¼“å­˜å±‚å¯ä»¥æ¢æˆ Redis é›†ç¾¤ï¼Œæ”¾åœ¨æœç´¢æœåŠ¡å‰é¢ã€‚çƒ­ç‚¹æŸ¥è¯¢ç›´æ¥å‘½ä¸­ç¼“å­˜ï¼Œä¸ç”¨è®¿é—®åç«¯ã€‚
>
> å¦å¤–è¿˜è¦è€ƒè™‘ç´¢å¼•æ›´æ–°çš„é—®é¢˜ï¼Œå¯ä»¥ç”¨åŒ buffer æ–¹æ¡ˆï¼šåå°æ„å»ºæ–°ç´¢å¼•ï¼Œå®ŒæˆååŸå­åˆ‡æ¢æŒ‡é’ˆï¼Œåšåˆ°æ— åœæœæ›´æ–°ã€‚"

### æ¨¡æ‹Ÿ 3ï¼šBM25 åŸç†

**é¢è¯•å®˜**ï¼šBM25 çš„å…¬å¼èƒ½å†™ä¸€ä¸‹å—ï¼Ÿ

> "å¯ä»¥ã€‚BM25 çš„æ ¸å¿ƒå…¬å¼æ˜¯ï¼š
>
> `BM25(t,d) = IDF(t) Ã— TF_norm(t,d)`
>
> å…¶ä¸­ IDF æ˜¯é€†æ–‡æ¡£é¢‘ç‡ï¼š`log((N - df + 0.5) / (df + 0.5) + 1)`
>
> TF_norm æ˜¯å½’ä¸€åŒ–çš„è¯é¢‘ï¼š`(tf Ã— (K1 + 1)) / (tf + K1 Ã— (1 - B + B Ã— |d| / avgdl))`
>
> K1 ä¸€èˆ¬å– 1.2ï¼Œæ§åˆ¶è¯é¢‘é¥±å’Œé€Ÿåº¦ï¼›B ä¸€èˆ¬å– 0.75ï¼Œæ§åˆ¶æ–‡æ¡£é•¿åº¦æƒ©ç½šã€‚
>
> ç›¸æ¯” TF-IDFï¼ŒBM25 çš„ä¼˜åŠ¿æ˜¯è¯é¢‘æœ‰é¥±å’Œä¸Šé™ï¼Œä¸ä¼šå› ä¸ºæŸä¸ªè¯å‡ºç°ç‰¹åˆ«å¤šæ¬¡å°±è¿‡åº¦ä¸»å¯¼åˆ†æ•°ã€‚"

---

## äº”ã€ç®€å†å†™æ³•

### ç®€æ´ç‰ˆï¼ˆä¸€é¡µç®€å†ï¼‰

```
é«˜æ€§èƒ½å…¨æ–‡æœç´¢å¼•æ“                              2024.11 - 2024.12
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ å®ç° BM25 æ’åºç®—æ³•å’Œå€’æ’ç´¢å¼•ï¼Œæ”¯æŒ 10 ä¸‡çº§ç½‘é¡µæ¯«ç§’çº§æ£€ç´¢
â€¢ è®¾è®¡ 16 åˆ†ç‰‡ LRU ç¼“å­˜ï¼ŒQPS æå‡ 4 å€ï¼›è½»é‡æ¨¡å¼å†…å­˜é™ä½ 95%
â€¢ æŠ€æœ¯æ ˆï¼šC++17 / wfrest / SimHash / å¤šçº¿ç¨‹
```

### æ ‡å‡†ç‰ˆï¼ˆæ¨èï¼‰

```
é«˜æ€§èƒ½å…¨æ–‡æœç´¢å¼•æ“                              2024.11 - 2024.12
æŠ€æœ¯æ ˆï¼šC++17 / wfrest / BM25 / SimHash / LRU
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€é¡¹ç›®èƒŒæ™¯ã€‘ç‹¬ç«‹è®¾è®¡å®ç°çš„ç”Ÿäº§çº§æœç´¢å¼•æ“ï¼Œæ”¯æŒç½‘é¡µæ£€ç´¢å’Œå…³é”®è¯æ¨è

ã€æ ¸å¿ƒåŠŸèƒ½ã€‘
â€¢ åŸºäº BM25 ç®—æ³•æ„å»ºå€’æ’ç´¢å¼•ï¼Œå®ç°ç›¸å…³æ€§æ’åºï¼ŒP99 å»¶è¿Ÿ < 20ms
â€¢ ä½¿ç”¨ SimHash å®ç°ç½‘é¡µæŒ‡çº¹å»é‡ï¼Œæ±‰æ˜è·ç¦» < 3 åˆ¤å®šç›¸ä¼¼ï¼Œå»é‡ç‡ > 95%
â€¢ å®ç°ç¼–è¾‘è·ç¦»ç®—æ³•çš„å…³é”®è¯æ¨èï¼Œæ”¯æŒæ‹¼å†™çº é”™å’Œæ¨¡ç³ŠåŒ¹é…

ã€æ€§èƒ½ä¼˜åŒ–ã€‘
â€¢ è®¾è®¡ 16 åˆ†ç‰‡ LRU ç¼“å­˜ï¼Œé™ä½é”ç«äº‰ 90%ï¼ŒQPS ä» 500 æå‡è‡³ 2000
â€¢ å®ç°è½»é‡çº§å†…å­˜æ¨¡å¼ï¼Œæ­£æ–‡æŒ‰éœ€è¯»å–ï¼Œå†…å­˜å ç”¨ä» 2GB é™è‡³ 85MB
â€¢ ä½¿ç”¨ partial_sort ä¼˜åŒ– TopKï¼Œæ’åºè€—æ—¶é™ä½ 85%

ã€å·¥ç¨‹å®è·µã€‘
â€¢ ä¿¡å·å¤„ç†å®ç°ä¼˜é›…é€€å‡ºï¼Œæ”¯æŒ Ctrl+C å®‰å…¨å…³é—­
â€¢ é…ç½®åˆ†ç¦»ã€å¼‚å¸¸æ•è·ã€å¥åº·æ£€æŸ¥ç­‰ç”Ÿäº§çº§ç‰¹æ€§
```

### è¯¦ç»†ç‰ˆï¼ˆé€‚åˆé¡¹ç›®ä»‹ç» PPTï¼‰

```
é¡¹ç›®åç§°ï¼šé«˜æ€§èƒ½å…¨æ–‡æœç´¢å¼•æ“
é¡¹ç›®å‘¨æœŸï¼š2024.11 - 2024.12ï¼ˆçº¦ 6 å‘¨ï¼‰
ä»£ç è§„æ¨¡ï¼š2500+ è¡Œ C++ ä»£ç 
é¡¹ç›®è§’è‰²ï¼šç‹¬ç«‹å¼€å‘

ä¸€ã€é¡¹ç›®èƒŒæ™¯
  ä¸ºäº†æ·±å…¥ç†è§£æœç´¢å¼•æ“åŸç†ï¼Œç‹¬ç«‹è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªæ”¯æŒä¸­æ–‡åˆ†è¯ã€
  ç›¸å…³æ€§æ’åºã€ç½‘é¡µå»é‡ã€å…³é”®è¯æ¨èçš„å…¨æ–‡æœç´¢ç³»ç»Ÿã€‚

äºŒã€æŠ€æœ¯æ¶æ„
  â€¢ ç¦»çº¿æ¨¡å—ï¼šXML è§£æ â†’ jieba åˆ†è¯ â†’ SimHash å»é‡ â†’ BM25 ç´¢å¼•æ„å»º
  â€¢ åœ¨çº¿æ¨¡å—ï¼šHTTP æœåŠ¡ â†’ LRU ç¼“å­˜ â†’ å€’æ’æ£€ç´¢ â†’ JSON å“åº”
  â€¢ å­˜å‚¨è®¾è®¡ï¼šæ”¯æŒä¼ ç»Ÿæ¨¡å¼ï¼ˆå…¨å†…å­˜ï¼‰å’Œè½»é‡æ¨¡å¼ï¼ˆç´¢å¼•å†…å­˜ + å†…å®¹ç£ç›˜ï¼‰

ä¸‰ã€æ ¸å¿ƒæŠ€æœ¯ç‚¹
  1. BM25 æ’åºç®—æ³•
     - ç›¸æ¯” TF-IDFï¼Œå¼•å…¥è¯é¢‘é¥±å’Œåº¦å’Œæ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–
     - ç¦»çº¿é¢„è®¡ç®—æƒé‡ï¼Œåœ¨çº¿åªåšåŠ æ³•èšåˆ

  2. SimHash ç½‘é¡µå»é‡
     - 64 ä½æŒ‡çº¹ + è¯é¢‘åŠ æƒ
     - æ±‰æ˜è·ç¦» < 3 åˆ¤å®šä¸ºç›¸ä¼¼æ–‡æ¡£

  3. åˆ†æ®µé” LRU ç¼“å­˜
     - 16 ä¸ªç‹¬ç«‹åˆ†ç‰‡ï¼Œhash(key) % 16 åˆ†æµ
     - åŸå­æ“ä½œç»Ÿè®¡å‘½ä¸­ç‡ï¼Œé¿å…é¢å¤–é”å¼€é”€

  4. å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆ
     - å…ƒæ•°æ®ä¸æ­£æ–‡åˆ†ç¦»å­˜å‚¨
     - æŸ¥è¯¢æ—¶æŒ‰åç§»é‡è¯»å–ç£ç›˜ï¼Œç»“åˆç¼“å­˜å‡å°‘ IO

å››ã€æ€§èƒ½æ•°æ®
  â€¢ ç´¢å¼•æ„å»ºï¼š10 ä¸‡ç½‘é¡µ / 45 ç§’
  â€¢ æŸ¥è¯¢å»¶è¿Ÿï¼šP50 5ms / P99 20ms
  â€¢ ååèƒ½åŠ›ï¼š2000 QPSï¼ˆ4 æ ¸æœåŠ¡å™¨ï¼‰
  â€¢ å†…å­˜ä¼˜åŒ–ï¼š2GB â†’ 85MBï¼ˆé™ä½ 95%ï¼‰

äº”ã€é¡¹ç›®æ”¶è·
  â€¢ æ·±å…¥ç†è§£äº†ä¿¡æ¯æ£€ç´¢çš„æ ¸å¿ƒç®—æ³•
  â€¢ æŒæ¡äº† C++ é«˜æ€§èƒ½æœåŠ¡ç«¯å¼€å‘æŠ€å·§
  â€¢ ç§¯ç´¯äº†æ€§èƒ½åˆ†æå’Œä¼˜åŒ–çš„å®æˆ˜ç»éªŒ
```

---

## å…­ã€æ³¨æ„äº‹é¡¹

### é¢è¯•æŠ€å·§

1. **å…ˆæ€»ååˆ†**ï¼šå…ˆç”¨ä¸€å¥è¯æ¦‚æ‹¬ï¼Œå†å±•å¼€ç»†èŠ‚
2. **æ•°æ®è¯´è¯**ï¼šQPS æå‡ 4 å€ã€å†…å­˜é™ä½ 95%ï¼Œæ¯”"ä¼˜åŒ–äº†å¾ˆå¤š"æœ‰è¯´æœåŠ›
3. **ä¸»åŠ¨å»¶ä¼¸**ï¼šå›ç­”å®Œåå¯ä»¥è¡¥å……"å¦‚æœæ‚¨æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥è¯¦ç»†è®²è®²..."
4. **æ‰¿è®¤è¾¹ç•Œ**ï¼šä¸æ‡‚çš„é—®é¢˜ç›´æ¥è¯´"è¿™ä¸ªæˆ‘äº†è§£ä¸å¤š"ï¼Œæ¯”èƒ¡è¯´å¥½

### å¸¸è§å‘

1. **åªè¯´ç”¨äº†ä»€ä¹ˆï¼Œä¸è¯´ä¸ºä»€ä¹ˆ**ï¼šé¢è¯•å®˜æ›´å…³å¿ƒä½ çš„æ€è€ƒè¿‡ç¨‹
2. **èƒŒä»£ç **ï¼šç°åœºå†™ä¸å‡ºæ¥ä¼šå¾ˆå°´å°¬ï¼Œç†è§£åŸç†æ¯”è®°ä»£ç é‡è¦
3. **è¿‡åº¦åŒ…è£…**ï¼šè¯´"åˆ†å¸ƒå¼"ä½†å…¶å®æ˜¯å•æœºï¼Œä¼šè¢«è¿½é—®éœ²é¦…
4. **å¿½ç•¥ç»†èŠ‚**ï¼šé—® K1=1.2 æ€ä¹ˆæ¥çš„ï¼Œè¯´ä¸å‡ºæ¥ä¼šå‡åˆ†

### å»ºè®®

- æŠŠè¿™ä»½æ–‡æ¡£çš„é—®ç­”å¤šç»ƒå‡ éï¼Œåšåˆ°è„±å£è€Œå‡º
- é‡ç‚¹æŒæ¡ BM25ã€LRUã€åˆ†æ®µé”ã€SimHash çš„åŸç†
- å‡†å¤‡å¥½æ‰©å±•æ€§é—®é¢˜çš„å›ç­”ï¼ˆåˆ†å¸ƒå¼ã€1 äº¿æ•°æ®ï¼‰

================================================================================
File: é¡¹ç›®æ”¹è¿›.md
Path: é¡¹ç›®æ”¹è¿›.md
Type: markdown
================================================================================
# é¡¹ç›®æ”¹è¿›è®¡åˆ’

æœ¬æ–‡æ¡£è®°å½•é¡¹ç›®çš„æ”¹è¿›è®¡åˆ’å’Œå®æ–½æ–¹æ¡ˆï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºã€‚

---

## æ”¹è¿›é¡¹æ€»è§ˆ

| ä¼˜å…ˆçº§ | æ”¹è¿›é¡¹ | çŠ¶æ€ | é¢„è®¡å·¥æ—¶ |
|--------|--------|------|----------|
| ğŸ”´ å¿…åš | æ€§èƒ½æµ‹è¯•æŠ¥å‘Š | âœ… å·²å®Œæˆ | - |
| ğŸ”´ å¿…åš | æ¶æ„å›¾ | âœ… å·²å®Œæˆ | - |
| ğŸ”´ å¿…åš | ä¼˜åŒ–æ•…äº‹å‡†å¤‡ | âœ… å·²å®Œæˆ | - |
| ğŸŸ¡ å»ºè®® | å•å…ƒæµ‹è¯• | â¬œ å¾…å¼€å§‹ | 4 å°æ—¶ |
| ğŸŸ¡ å»ºè®® | æŠ€æœ¯åšå®¢ | â¬œ å¾…å¼€å§‹ | 3 å°æ—¶ |
| ğŸŸ¢ å¯é€‰ | å¢é‡ç´¢å¼• | â¬œ å¾…å¼€å§‹ | 8 å°æ—¶ |
| ğŸŸ¢ å¯é€‰ | Docker éƒ¨ç½² | â¬œ å¾…å¼€å§‹ | 2 å°æ—¶ |
| ğŸŸ¢ å¯é€‰ | Redis ç¼“å­˜ | â¬œ å¾…å¼€å§‹ | 4 å°æ—¶ |

---

## ğŸ”´ å¿…åšé¡¹ï¼ˆ1-2 å¤©å†…å®Œæˆï¼‰

### 1. æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

**ç›®æ ‡**ï¼šç”¨æ•°æ®è¯æ˜é¡¹ç›®çš„æ€§èƒ½è¡¨ç°

**å®æ–½æ­¥éª¤**ï¼š

```bash
# 1. å®‰è£…å‹æµ‹å·¥å…·
sudo apt-get install wrk apache2-utils

# 2. åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > benchmark.sh << 'EOF'
#!/bin/bash

echo "=== ç´¢å¼•æ„å»ºæ€§èƒ½ ==="
time ./search_engine build

echo ""
echo "=== æŸ¥è¯¢æ€§èƒ½æµ‹è¯• ==="
echo "é¢„çƒ­..."
for i in {1..100}; do
    curl -s "http://localhost:8080/search?q=æµ‹è¯•" > /dev/null
done

echo "æ­£å¼æµ‹è¯• (30ç§’)..."
wrk -t4 -c100 -d30s "http://localhost:8080/search?q=æµ‹è¯•"

echo ""
echo "=== å†…å­˜å ç”¨ ==="
ps aux | grep search_engine | grep -v grep | awk '{print "Memory: " $6/1024 " MB"}'
EOF

chmod +x benchmark.sh
```

**æœŸæœ›è¾“å‡º**ï¼š

```
æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
============

æµ‹è¯•ç¯å¢ƒ
--------
- CPU: 4 æ ¸
- å†…å­˜: 8 GB
- æ•°æ®é‡: 10 ä¸‡ç½‘é¡µ

æµ‹è¯•ç»“æœ
--------
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ç´¢å¼•æ„å»º | 45 ç§’ |
| P50 å»¶è¿Ÿ | 5 ms |
| P99 å»¶è¿Ÿ | 20 ms |
| QPS | 2000+ |
| å†…å­˜ï¼ˆä¼ ç»Ÿï¼‰ | 1.8 GB |
| å†…å­˜ï¼ˆliteï¼‰ | 85 MB |
```

---

### 2. æ¶æ„å›¾

âœ… å·²åœ¨ README.md ä¸­å®Œæˆ

---

### 3. ä¼˜åŒ–æ•…äº‹å‡†å¤‡

âœ… å·²åœ¨ INTERVIEW_GUIDE.md ä¸­å®Œæˆ

---

## ğŸŸ¡ å»ºè®®åšé¡¹ï¼ˆ3-5 å¤©å†…å®Œæˆï¼‰

### 4. å•å…ƒæµ‹è¯•

**ç›®æ ‡**ï¼šå¢åŠ ä»£ç å¯ä¿¡åº¦ï¼Œå±•ç¤ºå·¥ç¨‹ç´ å…»

**å®æ–½æ­¥éª¤**ï¼š

1. å®‰è£… Google Testï¼š

```bash
sudo apt-get install libgtest-dev
cd /usr/src/gtest
sudo cmake .
sudo make
sudo cp lib/*.a /usr/lib
```

2. åˆ›å»ºæµ‹è¯•ç›®å½•å’Œæ–‡ä»¶ï¼š

```bash
mkdir -p test
```

3. ç¼–å†™æµ‹è¯•ç”¨ä¾‹ `test/test_lru_cache.cc`ï¼š

```cpp
#include <gtest/gtest.h>
#include "../include/LRUCache.h"
#include <thread>
#include <vector>

// åŸºæœ¬åŠŸèƒ½æµ‹è¯•
TEST(LRUCacheTest, BasicGetPut) {
    SearchCache cache(3);
    cache.put("a", "1");
    cache.put("b", "2");

    string val;
    EXPECT_TRUE(cache.get("a", val));
    EXPECT_EQ(val, "1");
    EXPECT_TRUE(cache.get("b", val));
    EXPECT_EQ(val, "2");
}

// æ·˜æ±°æµ‹è¯•
TEST(LRUCacheTest, Eviction) {
    SearchCache cache(2);
    cache.put("a", "1");
    cache.put("b", "2");
    cache.put("c", "3");  // åº”è¯¥æ·˜æ±°æŸä¸ªåˆ†ç‰‡ä¸­æœ€è€çš„

    // ç”±äºåˆ†æ®µé”ï¼Œæ·˜æ±°è¡Œä¸ºå–å†³äº hash åˆ†å¸ƒ
    // è‡³å°‘åº”è¯¥èƒ½å­˜ 2 ä¸ª
    EXPECT_LE(cache.size(), 3);
}

// æ›´æ–°æµ‹è¯•
TEST(LRUCacheTest, Update) {
    SearchCache cache(10);
    cache.put("a", "1");
    cache.put("a", "2");

    string val;
    EXPECT_TRUE(cache.get("a", val));
    EXPECT_EQ(val, "2");
}

// å¹¶å‘æµ‹è¯•
TEST(LRUCacheTest, ConcurrentAccess) {
    SearchCache cache(1000);
    std::vector<std::thread> threads;

    // 10 ä¸ªçº¿ç¨‹å¹¶å‘å†™å…¥
    for (int i = 0; i < 10; i++) {
        threads.emplace_back([&cache, i]() {
            for (int j = 0; j < 1000; j++) {
                cache.put(std::to_string(i * 1000 + j), "value");
            }
        });
    }

    for (auto& t : threads) t.join();

    // æ²¡æœ‰å´©æºƒå’Œæ­»é”å°±æ˜¯æˆåŠŸ
    EXPECT_GT(cache.size(), 0);
}

// å‘½ä¸­ç‡ç»Ÿè®¡æµ‹è¯•
TEST(LRUCacheTest, HitRate) {
    SearchCache cache(10);
    cache.put("a", "1");

    string val;
    cache.get("a", val);  // hit
    cache.recordQuery(true);
    cache.get("b", val);  // miss
    cache.recordQuery(false);

    EXPECT_EQ(cache.hitRate(), 0.5);
}

int main(int argc, char **argv) {
    testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
```

4. ç¼–å†™æµ‹è¯•ç”¨ä¾‹ `test/test_bm25.cc`ï¼š

```cpp
#include <gtest/gtest.h>
#include "../include/InvertIndex.h"
#include "../include/WebPage.h"
#include "../include/SplitTool.h"
#include <cmath>

class BM25Test : public ::testing::Test {
protected:
    void SetUp() override {
        // åˆå§‹åŒ–åˆ†è¯å·¥å…·å’Œç´¢å¼•
    }
};

// IDF è®¡ç®—æµ‹è¯•
TEST(BM25Test, IDFCalculation) {
    // df=1, N=100 æ—¶ï¼ŒIDF åº”è¯¥è¾ƒé«˜
    // df=50, N=100 æ—¶ï¼ŒIDF åº”è¯¥è¾ƒä½
    InvertIndex index;
    // é€šè¿‡ public æ¥å£æµ‹è¯• BM25 è¡Œä¸º
}

// æ’åºæ­£ç¡®æ€§æµ‹è¯•
TEST(BM25Test, RankingOrder) {
    // åŒ…å«æŸ¥è¯¢è¯æ›´å¤šçš„æ–‡æ¡£åº”è¯¥æ’åœ¨å‰é¢
}
```

5. æ·»åŠ  Makefile æµ‹è¯•ç›®æ ‡ï¼š

```makefile
# æ·»åŠ åˆ° Makefile
TEST_SRCS = test/test_lru_cache.cc
TEST_OBJS = $(TEST_SRCS:.cc=.o)

test: $(TEST_OBJS)
	$(CXX) $(CXXFLAGS) -o run_tests $(TEST_OBJS) -lgtest -lgtest_main -lpthread
	./run_tests

.PHONY: test
```

---

### 5. æŠ€æœ¯åšå®¢

**ç›®æ ‡**ï¼šå¢åŠ æ›å…‰ï¼Œå±•ç¤ºè¡¨è¾¾èƒ½åŠ›

**å»ºè®®å‘å¸ƒå¹³å°**ï¼š
- æ˜é‡‘
- CSDN
- çŸ¥ä¹ä¸“æ 
- ä¸ªäººåšå®¢

**æ–‡ç« å¤§çº²**ï¼š

```markdown
# ä»é›¶å®ç°ä¸€ä¸ªé«˜æ€§èƒ½æœç´¢å¼•æ“ï¼ˆC++ï¼‰

## å‰è¨€
- ä¸ºä»€ä¹ˆåšè¿™ä¸ªé¡¹ç›®
- é¡¹ç›®èƒ½è¾¾åˆ°ä»€ä¹ˆæ•ˆæœ

## æ•´ä½“æ¶æ„
- æ¶æ„å›¾
- æ¨¡å—åˆ’åˆ†
- æ•°æ®æµ

## æ ¸å¿ƒç®—æ³•è¯¦è§£

### BM25 æ’åº
- TF-IDF çš„ä¸è¶³
- BM25 çš„æ”¹è¿›
- ä»£ç å®ç°

### SimHash å»é‡
- åŸç†è®²è§£
- æ±‰æ˜è·ç¦»
- å®é™…æ•ˆæœ

## æ€§èƒ½ä¼˜åŒ–å®æˆ˜

### åˆ†æ®µé” LRU
- é—®é¢˜å‘ç°
- è§£å†³æ–¹æ¡ˆ
- æ•ˆæœå¯¹æ¯”

### å†…å­˜ä¼˜åŒ–
- é—®é¢˜åˆ†æ
- åˆ†ç¦»å­˜å‚¨æ–¹æ¡ˆ
- æ•ˆæœå¯¹æ¯”

## è¸©å‘è®°å½•
- å‘1: xxx
- å‘2: xxx

## æ€»ç»“
- å­¦åˆ°äº†ä»€ä¹ˆ
- æœªæ¥å±•æœ›

## æºç 
- GitHub é“¾æ¥
```

---

## ğŸŸ¢ å¯é€‰åšé¡¹ï¼ˆé”¦ä¸Šæ·»èŠ±ï¼‰

### 6. å¢é‡ç´¢å¼•æ”¯æŒ

**ç›®æ ‡**ï¼šæ”¯æŒå®æ—¶æ·»åŠ æ–‡æ¡£ï¼Œä¸éœ€è¦å…¨é‡é‡å»º

**è®¾è®¡æ–¹æ¡ˆ**ï¼š

```cpp
// InvertIndex.h æ·»åŠ 
class InvertIndex {
public:
    // å¢é‡æ·»åŠ æ–‡æ¡£
    void addDocument(shared_ptr<WebPage> page);

    // æ ‡è®°åˆ é™¤æ–‡æ¡£
    void removeDocument(int docId);

    // åå°åˆå¹¶ï¼ˆå®šæœŸæ‰§è¡Œï¼‰
    void merge();

private:
    // ä¸»ç´¢å¼•ï¼ˆåªè¯»ï¼Œå¤§ï¼‰
    unordered_map<string, vector<InvertIndexItem>> _mainIndex;

    // å¢é‡ç´¢å¼•ï¼ˆè¯»å†™ï¼Œå°ï¼‰
    unordered_map<string, vector<InvertIndexItem>> _deltaIndex;
    mutex _deltaMutex;

    // åˆ é™¤é›†åˆ
    unordered_set<int> _deletedDocs;
    mutex _deleteMutex;
};

// æŸ¥è¯¢æ—¶åˆå¹¶ä¸¤ä¸ªç´¢å¼•çš„ç»“æœ
vector<pair<int, double>> InvertIndex::search(...) {
    // 1. æŸ¥ä¸»ç´¢å¼•
    // 2. æŸ¥å¢é‡ç´¢å¼•
    // 3. è¿‡æ»¤å·²åˆ é™¤æ–‡æ¡£
    // 4. åˆå¹¶æ’åº
}
```

---

### 7. Docker éƒ¨ç½²

**ç›®æ ‡**ï¼šä¸€é”®éƒ¨ç½²ï¼Œæ–¹ä¾¿æ¼”ç¤º

**Dockerfile**ï¼š

```dockerfile
FROM ubuntu:22.04

# å®‰è£…ä¾èµ–
RUN apt-get update && apt-get install -y \
    g++ make libssl-dev git cmake

# å®‰è£… workflow
RUN git clone https://github.com/sogou/workflow.git /workflow && \
    cd /workflow && make -j4 && make install

# å®‰è£… wfrest
RUN git clone https://github.com/wfrest/wfrest.git /wfrest && \
    cd /wfrest && make -j4 && make install

# å¤åˆ¶é¡¹ç›®
WORKDIR /app
COPY . .

# ç¼–è¯‘
RUN make clean && make

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨å‘½ä»¤
CMD ["./search_engine", "server"]
```

**docker-compose.yml**ï¼š

```yaml
version: '3'
services:
  search:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data
      - ./conf:/app/conf
    restart: unless-stopped
```

**ä½¿ç”¨æ–¹å¼**ï¼š

```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

---

### 8. Redis ç¼“å­˜

**ç›®æ ‡**ï¼šæ”¯æŒåˆ†å¸ƒå¼ç¼“å­˜ï¼Œæé«˜å¯æ‰©å±•æ€§

**è®¾è®¡æ–¹æ¡ˆ**ï¼š

```cpp
// RedisCache.h
class RedisCache {
public:
    RedisCache(const string& host, int port);

    bool get(const string& key, string& value);
    void put(const string& key, const string& value, int ttl = 3600);

private:
    // ä½¿ç”¨ hiredis æˆ– redis-plus-plus
};

// SearchServer ä¸­ä½¿ç”¨
class SearchServer {
    // äºŒçº§ç¼“å­˜ï¼šæœ¬åœ° LRU + Redis
    shared_ptr<SearchCache> _localCache;
    shared_ptr<RedisCache> _redisCache;

    string handleSearch(const string& query) {
        string result;

        // L1: æœ¬åœ°ç¼“å­˜
        if (_localCache->get(query, result)) {
            return result;
        }

        // L2: Redis
        if (_redisCache && _redisCache->get(query, result)) {
            _localCache->put(query, result);
            return result;
        }

        // å®é™…æœç´¢
        result = doSearch(query);

        // å†™å…¥ç¼“å­˜
        _localCache->put(query, result);
        if (_redisCache) {
            _redisCache->put(query, result);
        }

        return result;
    }
};
```

---

## æ”¹è¿›æ£€æŸ¥æ¸…å•

é¢è¯•å‰ç¡®ä¿å®Œæˆä»¥ä¸‹æ£€æŸ¥ï¼š

- [ ] èƒ½æµç•…è®²è¿° 3 ä¸ªä¼˜åŒ–æ•…äº‹
- [ ] èƒ½æ‰‹å†™ BM25 å…¬å¼
- [ ] èƒ½è§£é‡Šåˆ†æ®µé”åŸç†å’Œç¼ºç‚¹
- [ ] èƒ½å›ç­”"1 äº¿æ•°æ®æ€ä¹ˆåŠ"
- [ ] æœ‰æ€§èƒ½æµ‹è¯•æ•°æ®æ”¯æ’‘
- [ ] ä»£ç èƒ½æ­£å¸¸ç¼–è¯‘è¿è¡Œ
- [ ] èƒ½ç°åœºæ¼”ç¤ºæœç´¢åŠŸèƒ½

================================================================================
File: é¡¹ç›®ç»“æ„.md
Path: é¡¹ç›®ç»“æ„.md
Type: markdown
================================================================================
# Engine æœç´¢å¼•æ“ - é¡¹ç›®æ¶æ„å…¨æ™¯å›¾

## ä¸€ã€ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Engine æœç´¢å¼•æ“ç³»ç»Ÿ                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¡¨ç°å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚   â”‚  SearchServer (HTTPæœåŠ¡)                                              â”‚  â”‚   â”‚
â”‚  â”‚   â”‚  â”œâ”€ GET /search?q=xxx  â†’ æœç´¢æ¥å£ (è¿”å›JSON)                          â”‚  â”‚   â”‚
â”‚  â”‚   â”‚  â”œâ”€ GET /suggest?q=xxx â†’ å…³é”®è¯æ¨èæ¥å£                               â”‚  â”‚   â”‚
â”‚  â”‚   â”‚  â”œâ”€ GET /health        â†’ å¥åº·æ£€æŸ¥ (ç¼“å­˜å‘½ä¸­ç‡)                        â”‚  â”‚   â”‚
â”‚  â”‚   â”‚  â””â”€ GET /              â†’ å‰ç«¯æœç´¢é¡µé¢                                 â”‚  â”‚   â”‚
â”‚  â”‚   â”‚  [åŸºäº wfrest æ¡†æ¶, ç›‘å¬ 0.0.0.0:8080]                                â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                           â†“ è°ƒç”¨                                            â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚   â”‚  static/index.html (å‰ç«¯é¡µé¢)                                        â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  â””â”€ Fetch API å¼‚æ­¥è¯·æ±‚ â†’ å±•ç¤ºæœç´¢ç»“æœ                                 â”‚   â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                        â”‚                                            â”‚
â”‚                                        â†“ ä¾èµ–                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸šåŠ¡é€»è¾‘å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚   LRUCache      â”‚    â”‚  InvertIndex     â”‚    â”‚ KeywordRecommender    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚   (æœç´¢ç¼“å­˜)     â”‚    â”‚  (å€’æ’ç´¢å¼•)       â”‚    â”‚ (å…³é”®è¯æ¨è)          â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚    â”‚                  â”‚    â”‚                       â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ å®¹é‡: 1000    â”‚    â”‚ â€¢ BM25 æƒé‡è®¡ç®—   â”‚    â”‚ â€¢ ç¼–è¾‘è·ç¦»ç®—æ³•        â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ 16åˆ†ç‰‡é”      â”‚    â”‚ â€¢ k1=1.2, b=0.75 â”‚    â”‚ â€¢ å€™é€‰è¯æ’åº          â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ å‘½ä¸­ç‡ç»Ÿè®¡    â”‚    â”‚ â€¢ æŒ‰æƒé‡æ’åº      â”‚    â”‚ â€¢ TopK æ¨è           â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ çº¿ç¨‹å®‰å…¨      â”‚    â”‚ â€¢ äºŒè¿›åˆ¶åºåˆ—åŒ–    â”‚    â”‚ â€¢ UTF-8 å­—ç¬¦å¤„ç†      â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â”‚           â”‚                      â”‚                          â”‚                â”‚  â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  â”‚
â”‚  â”‚                                  â†“ ä¾èµ–                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                        â”‚                                            â”‚
â”‚                                        â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è®¿é—®å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  â”‚
â”‚  â”‚  â”‚     PageLib         â”‚        â”‚   DictProducer       â”‚                     â”‚  â”‚
â”‚  â”‚  â”‚   (ç½‘é¡µåº“ç®¡ç†)       â”‚        â”‚   (è¯å…¸ç”Ÿæˆå™¨)        â”‚                     â”‚  â”‚
â”‚  â”‚  â”‚                     â”‚        â”‚                      â”‚                     â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ åŠ è½½ XML æ–‡æ¡£      â”‚        â”‚ â€¢ è¯é¢‘ç»Ÿè®¡            â”‚                     â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ ç®¡ç† WebPage åˆ—è¡¨  â”‚        â”‚ â€¢ å­—ç¬¦ç´¢å¼•æ„å»º        â”‚                     â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ åˆ†ç¦»å­˜å‚¨(lite)    â”‚        â”‚ â€¢ UTF-8 æ‹†å­—          â”‚                     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â”‚             â”‚                               â”‚                                 â”‚  â”‚
â”‚  â”‚             â†“ ä½¿ç”¨                          â†“ ä¾èµ–                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚                        WebPage (æ–‡æ¡£å¯¹è±¡)                             â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                                                                      â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  å±æ€§: docId | title | url | content | wordsMap(è¯é¢‘)                â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  æ–¹æ³•: processDoc() | getSimhash() | getSummary() | hammingDistance()â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                        â”‚                                            â”‚
â”‚                                        â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å·¥å…·/åŸºç¡€å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ PageLibPreprocessor   â”‚    â”‚           SplitTool (åˆ†è¯å·¥å…·)              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚    (é¢„å¤„ç†å™¨)          â”‚    â”‚                                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚                       â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ SimHash è®¡ç®—        â”‚    â”‚  â”‚      JiebaSplitTool (å…·ä½“å®ç°)       â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ æ±‰æ˜è·ç¦»åˆ¤é‡        â”‚â†â”€â”€â”€â”‚  â”‚                                      â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ é˜ˆå€¼: 3 bits        â”‚    â”‚  â”‚  â€¢ å°è£… cppjieba (pImpl æ¨¡å¼)        â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â€¢ åœç”¨è¯è¿‡æ»¤                        â”‚  â”‚ â”‚  â”‚
â”‚  â”‚                               â”‚  â”‚  â€¢ vector<string> cut(sentence)     â”‚  â”‚ â”‚  â”‚
â”‚  â”‚                               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â”‚
â”‚  â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚
â”‚  â”‚  â”‚                    Configuration (é…ç½®ç®¡ç† - å•ä¾‹æ¨¡å¼)                    â”‚â”‚  â”‚
â”‚  â”‚  â”‚                                                                          â”‚â”‚  â”‚
â”‚  â”‚  â”‚  é…ç½®é¡¹: server_ip | server_port | data_path | index_path | cache_size  â”‚â”‚  â”‚
â”‚  â”‚  â”‚          dict_path | model_path | idf_path | stop_word_path              â”‚â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€æ¨¡å—ä¾èµ–å…³ç³»å›¾

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   main.cc   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                     â”‚                     â”‚
           â†“                     â†“                     â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Configuration â”‚    â”‚  build æ¨¡å¼   â”‚    â”‚ server æ¨¡å¼   â”‚
   â”‚   (å•ä¾‹)      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚                    â”‚
           â†‘                    â”‚                    â”‚
           â”‚                    â†“                    â†“
           â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    PageLib     â”‚   â”‚  SearchServer  â”‚
                       â”‚  (åŠ è½½ XML)    â”‚   â”‚  (HTTP æœåŠ¡)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                   â”‚
                                â†“                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                    â”‚ PageLibPreprocessor   â”‚       â”‚
                    â”‚   (SimHash å»é‡)      â”‚       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                â”‚                   â”‚
                                â†“                   â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
                       â”‚  InvertIndex   â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚ (BM25 ç´¢å¼•)    â”‚           â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                â”‚                   â”‚
                                â†“                   â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
                       â”‚ DictProducer   â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚  (è¯å…¸ç”Ÿæˆ)    â”‚           â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                â”‚                   â”‚
                                â†“                   â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       KeywordRecommender          â”‚
                    â”‚     (ç¼–è¾‘è·ç¦» + TopK æ¨è)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†‘
                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           LRUCache               â”‚
                    â”‚      (æŸ¥è¯¢ç»“æœç¼“å­˜)               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        æ‰€æœ‰æ¨¡å—å…±åŒä¾èµ–
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    SplitTool / JiebaSplitTool     â”‚
                    â”‚         (ä¸­æ–‡åˆ†è¯)                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          WebPage                  â”‚
                    â”‚   (æ–‡æ¡£å¯¹è±¡ + SimHash è®¡ç®—)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€æ•°æ®æµå‘å›¾

### 3.1 ç¦»çº¿æ„å»ºæµç¨‹ (build æ¨¡å¼)

```
  data/*.xml                     cppjiebaè¯å…¸
       â”‚                              â”‚
       â†“                              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PageLib    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  SplitTool  â”‚
  â”‚  åŠ è½½æ–‡æ¡£    â”‚    åˆ†è¯       â”‚  ä¸­æ–‡åˆ†è¯    â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ åˆ›å»º WebPage å¯¹è±¡
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                         WebPage[]                                â”‚
  â”‚  æ¯ä¸ªæ–‡æ¡£: docId, title, url, content, wordsMap(è¯â†’é¢‘)          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                                             â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Preprocessor    â”‚                         â”‚  DictProducer   â”‚
  â”‚ SimHashå»é‡     â”‚                         â”‚  è¯å…¸ç»Ÿè®¡        â”‚
  â”‚ æ±‰æ˜è·ç¦»<3å‰”é™¤   â”‚                         â”‚  å­—ç¬¦ç´¢å¼•æ„å»º    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                           â”‚
           â†“                                           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ processedPages  â”‚                         â”‚ dict.dat        â”‚
  â”‚ (å»é‡åçš„æ–‡æ¡£)   â”‚                         â”‚ dict_index.dat  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                       InvertIndex æ„å»º                          â”‚
  â”‚                                                                 â”‚
  â”‚  Step 1: ç»Ÿè®¡ DF (æ–‡æ¡£é¢‘ç‡)                                      â”‚
  â”‚  Step 2: è®¡ç®—æ–‡æ¡£é•¿åº¦ & å¹³å‡é•¿åº¦                                  â”‚
  â”‚  Step 3: è®¡ç®— BM25 æƒé‡                                          â”‚
  â”‚          IDF Ã— (TFÃ—(k1+1)) / (TF + k1Ã—(1-b+bÃ—len/avgLen))      â”‚
  â”‚  Step 4: æŒ‰æƒé‡æ’åºå€’æ’åˆ—è¡¨                                      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â†“
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   index.dat     â”‚
                       â”‚  (å€’æ’ç´¢å¼•æ–‡ä»¶)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 åœ¨çº¿æŸ¥è¯¢æµç¨‹ (server æ¨¡å¼)

```
                    æµè§ˆå™¨è¯·æ±‚: GET /search?q=ç§‘æŠ€
                                 â”‚
                                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                         SearchServer                                   â”‚
  â”‚                                                                        â”‚
  â”‚   â‘   URLè§£ç : %E7%A7%91%E6%8A%80 â†’ "ç§‘æŠ€"                              â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“                                             â”‚
  â”‚   â‘¡  æ£€æŸ¥ LRUCache â”€â”€â†’ å‘½ä¸­? â”€â”€â†’ ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ                       â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“ æœªå‘½ä¸­                                       â”‚
  â”‚   â‘¢  SplitTool.cut("ç§‘æŠ€") â†’ ["ç§‘æŠ€"]                                  â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“                                             â”‚
  â”‚   â‘£  InvertIndex.search(["ç§‘æŠ€"]) â†’ [(docId:1, score:3.6), ...]       â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“                                             â”‚
  â”‚   â‘¤  PageLib.getPage(docId) â†’ WebPageå¯¹è±¡                             â”‚
  â”‚       WebPage.getSummary(queryWords) â†’ æ‘˜è¦                            â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“                                             â”‚
  â”‚   â‘¥  ç”Ÿæˆ JSON å“åº”                                                    â”‚
  â”‚       {                                                                â”‚
  â”‚         "query": "ç§‘æŠ€",                                               â”‚
  â”‚         "total": 20,                                                   â”‚
  â”‚         "results": [{docId, title, url, summary, score}, ...]         â”‚
  â”‚       }                                                                â”‚
  â”‚                          â”‚                                             â”‚
  â”‚                          â†“                                             â”‚
  â”‚   â‘¦  å­˜å…¥ LRUCache                                                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â†“
                           JSON å“åº”è¿”å›
```

---

## å››ã€æ–‡ä»¶ç»“æ„æ€»è§ˆ

```
Engine/
â”œâ”€â”€ include/                          # å¤´æ–‡ä»¶ (æ¥å£å®šä¹‰)
â”‚   â”œâ”€â”€ Configuration.h              # é…ç½®ç®¡ç† [å•ä¾‹æ¨¡å¼]
â”‚   â”œâ”€â”€ SplitTool.h                  # åˆ†è¯æ¥å£ [ç­–ç•¥æ¨¡å¼ + pImpl]
â”‚   â”œâ”€â”€ WebPage.h                    # æ–‡æ¡£ç±» [SimHash]
â”‚   â”œâ”€â”€ WebPageMeta.h                # è½»é‡å…ƒæ•°æ® [å†…å­˜ä¼˜åŒ–]
â”‚   â”œâ”€â”€ PageLib.h                    # æ–‡æ¡£åº“ç®¡ç†
â”‚   â”œâ”€â”€ PageLibPreprocessor.h        # å»é‡é¢„å¤„ç†
â”‚   â”œâ”€â”€ InvertIndex.h                # å€’æ’ç´¢å¼• [BM25]
â”‚   â”œâ”€â”€ SearchServer.h               # HTTPæœåŠ¡ [wfrest]
â”‚   â”œâ”€â”€ DictProducer.h               # è¯å…¸ç”Ÿæˆ
â”‚   â”œâ”€â”€ KeywordRecommender.h         # å…³é”®è¯æ¨è [ç¼–è¾‘è·ç¦»]
â”‚   â””â”€â”€ LRUCache.h                   # LRUç¼“å­˜ [åˆ†æ®µé”]
â”‚
â”œâ”€â”€ src/                              # å®ç°æ–‡ä»¶
â”‚   â”œâ”€â”€ main.cc                      # å…¥å£ (build/server/server-lite)
â”‚   â”œâ”€â”€ Configuration.cc
â”‚   â”œâ”€â”€ SplitTool.cc                 # cppjiebaå°è£…
â”‚   â”œâ”€â”€ WebPage.cc                   # XMLè§£æ + SimHash
â”‚   â”œâ”€â”€ PageLib.cc                   # ç›®å½•éå† + åˆ†ç¦»å­˜å‚¨
â”‚   â”œâ”€â”€ PageLibPreprocessor.cc       # å»é‡é€»è¾‘
â”‚   â”œâ”€â”€ InvertIndex.cc               # BM25è®¡ç®—
â”‚   â”œâ”€â”€ SearchServer.cc              # HTTPè·¯ç”± + URLè§£ç 
â”‚   â”œâ”€â”€ DictProducer.cc              # è¯å…¸æ„å»º
â”‚   â””â”€â”€ KeywordRecommender.cc        # æ¨èç®—æ³•
â”‚
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ search.conf                  # é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ news_100000.xml              # æµ‹è¯•è¯­æ–™ (10ä¸‡ç¯‡æ–°é—»)
â”‚   â”œâ”€â”€ index.dat                    # å€’æ’ç´¢å¼•
â”‚   â”œâ”€â”€ pagelib.dat                  # ç½‘é¡µåº“
â”‚   â”œâ”€â”€ pagelib.dat.meta             # å…ƒæ•°æ® (liteæ¨¡å¼)
â”‚   â”œâ”€â”€ pagelib.dat.content          # æ­£æ–‡å†…å®¹ (liteæ¨¡å¼)
â”‚   â”œâ”€â”€ dict.dat                     # è¯å…¸æ–‡ä»¶
â”‚   â””â”€â”€ dict_index.dat               # å­—ç¬¦ç´¢å¼•
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html                   # å‰ç«¯æœç´¢é¡µé¢
â”‚
â”œâ”€â”€ benchmark.sh                     # æ€§èƒ½æµ‹è¯•è„šæœ¬
â”œâ”€â”€ Makefile                         # ç¼–è¯‘é…ç½®
â”œâ”€â”€ README.md                        # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ å‹åŠ›æµ‹è¯•.md                       # æ€§èƒ½æµ‹è¯•æŠ¥å‘Š (QPS 48850)
â”œâ”€â”€ é¡¹ç›®æ”¹è¿›.md                       # æ”¹è¿›è®¡åˆ’
â”œâ”€â”€ é¡¹ç›®ç»“æ„.md                       # æœ¬æ–‡æ¡£
â”œâ”€â”€ å­¦ä¹ é¡ºåº.txt                      # ä»£ç é˜…è¯»é¡ºåº
â””â”€â”€ é¢è¯•æŒ‡å¯¼.md                       # é¢è¯•å‡†å¤‡æŒ‡å—
```

---

## äº”ã€æ ¸å¿ƒæ¨¡å—åŠŸèƒ½è¯´æ˜

| æ¨¡å— | æ–‡ä»¶ | æ ¸å¿ƒåŠŸèƒ½ | è®¾è®¡æ¨¡å¼ |
|------|------|----------|----------|
| **Configuration** | Configuration.h/cc | åŠ è½½é…ç½®æ–‡ä»¶ï¼Œå…¨å±€é…ç½®ç®¡ç† | å•ä¾‹æ¨¡å¼ |
| **SplitTool** | SplitTool.h/cc | ä¸­æ–‡åˆ†è¯ï¼Œå°è£…cppjieba | ç­–ç•¥æ¨¡å¼ + pImpl |
| **WebPage** | WebPage.h/cc | æ–‡æ¡£è§£æï¼ŒSimHashè®¡ç®—ï¼Œæ‘˜è¦ç”Ÿæˆ | - |
| **WebPageMeta** | WebPageMeta.h | è½»é‡å…ƒæ•°æ®ï¼Œé…åˆç£ç›˜å­˜å‚¨ | - |
| **PageLib** | PageLib.h/cc | åŠ è½½XMLæ–‡æ¡£ï¼Œç®¡ç†WebPageåˆ—è¡¨ | - |
| **PageLibPreprocessor** | PageLibPreprocessor.h/cc | SimHashå»é‡ï¼Œæ±‰æ˜è·ç¦»åˆ¤æ–­ | - |
| **InvertIndex** | InvertIndex.h/cc | BM25æƒé‡è®¡ç®—ï¼Œå€’æ’ç´¢å¼•æ„å»º/æŸ¥è¯¢ | - |
| **DictProducer** | DictProducer.h/cc | è¯é¢‘ç»Ÿè®¡ï¼Œå­—ç¬¦ç´¢å¼•æ„å»º | - |
| **KeywordRecommender** | KeywordRecommender.h/cc | ç¼–è¾‘è·ç¦»è®¡ç®—ï¼ŒTopKæ¨è | - |
| **LRUCache** | LRUCache.h | 16åˆ†ç‰‡ç¼“å­˜ï¼ŒO(1)è¯»å†™ | æ¨¡æ¿ç±» |
| **SearchServer** | SearchServer.h/cc | HTTPæœåŠ¡ï¼ŒURLè§£ç ï¼ŒJSONå“åº” | - |

---

## å…­ã€æ ¸å¿ƒç®—æ³•ä¸€è§ˆ

| ç®—æ³• | ç”¨é€” | æ‰€åœ¨æ¨¡å— | å¤æ‚åº¦ |
|------|------|----------|--------|
| **BM25** | æœç´¢ç»“æœæ’åº | InvertIndex | O(n) |
| **SimHash** | æ–‡æ¡£å»é‡ | WebPage | O(è¯æ•°) |
| **æ±‰æ˜è·ç¦»** | ç›¸ä¼¼åº¦åˆ¤æ–­ | WebPage | O(1) |
| **ç¼–è¾‘è·ç¦»** | å…³é”®è¯æ¨è | KeywordRecommender | O(mÃ—n) |
| **LRU** | çƒ­é—¨æŸ¥è¯¢ç¼“å­˜ | LRUCache | O(1) |

### BM25 å…¬å¼

```
BM25(q, d) = Î£ IDF(qi) Ã— (TF(qi,d) Ã— (k1 + 1)) / (TF(qi,d) + k1 Ã— (1 - b + b Ã— L(d) / L_avg))

å…¶ä¸­:
- IDF(qi) = log((N - n(qi) + 0.5) / (n(qi) + 0.5) + 1)
- k1 = 1.2 (è¯é¢‘é¥±å’Œå‚æ•°)
- b = 0.75 (æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–å‚æ•°)
- N = æ€»æ–‡æ¡£æ•°
- n(qi) = åŒ…å«è¯qiçš„æ–‡æ¡£æ•°
- L(d) = æ–‡æ¡£dçš„é•¿åº¦
- L_avg = å¹³å‡æ–‡æ¡£é•¿åº¦
```

### SimHash å»é‡

```
1. å¯¹æ–‡æ¡£åˆ†è¯å¾—åˆ° words[]
2. åˆå§‹åŒ– hashVector[64] = 0
3. for each word in words:
     hash = Jenkins_Hash(word)
     for i in 0..63:
         if (hash & (1 << i)):
             hashVector[i] += word_frequency
         else:
             hashVector[i] -= word_frequency
4. simHash = 0
   for i in 0..63:
       if hashVector[i] > 0:
           simHash |= (1 << i)
5. ä¸¤ä¸ªæ–‡æ¡£ç›¸ä¼¼ <=> hammingDistance(simHash1, simHash2) < 3
```

---

## ä¸ƒã€è¿è¡Œæ–¹å¼

### æ„å»ºç´¢å¼•

```bash
make clean && make all
./search_engine build
```

### å¯åŠ¨æœåŠ¡

```bash
# ä¼ ç»Ÿæ¨¡å¼ (å…¨å†…å­˜)
./search_engine server

# è½»é‡æ¨¡å¼ (å†…å­˜ä¼˜åŒ–)
./search_engine server-lite
```

### è®¿é—®æ¥å£

| æ¥å£ | URL | è¯´æ˜ |
|------|-----|------|
| æœç´¢ | `http://localhost:8080/search?q=ç§‘æŠ€` | è¿”å›JSONæœç´¢ç»“æœ |
| æ¨è | `http://localhost:8080/suggest?q=æœç´¢` | è¿”å›æ¨èè¯åˆ—è¡¨ |
| å¥åº·æ£€æŸ¥ | `http://localhost:8080/health` | è¿”å›ç¼“å­˜çŠ¶æ€ |
| å‰ç«¯é¡µé¢ | `http://localhost:8080/` | æœç´¢ç•Œé¢ |

---

## å…«ã€æ€§èƒ½æŒ‡æ ‡

> æµ‹è¯•ç¯å¢ƒï¼š2 æ ¸ 4G è™šæ‹Ÿæœºï¼Œ10 ä¸‡ç¯‡æ–‡æ¡£

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ç´¢å¼•æ„å»ºæ—¶é—´ | 102 ç§’ |
| æŸ¥è¯¢å»¶è¿Ÿ P50 | 1.78 ms |
| æŸ¥è¯¢å»¶è¿Ÿ P99 | 6.14 ms |
| ååé‡ QPS | **48,850** |
| å†…å­˜å ç”¨ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰ | 631 MB |
| å†…å­˜å ç”¨ï¼ˆè½»é‡æ¨¡å¼ï¼‰ | ~100 MB |

